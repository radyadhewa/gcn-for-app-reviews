{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "# LDA\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# aspect\n",
    "from gensim.models import FastText\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# model\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_tokenized</th>\n",
       "      <th>final_sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['senang']</td>\n",
       "      <td>senang</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['mentok', 'melulu', 'di', 'pin', 'tiap', 'mau...</td>\n",
       "      <td>mentok melulu di pin tiap mau log in tidak bis...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['aplikasi', 'sangat', 'bantu', 'saya', 'yang'...</td>\n",
       "      <td>aplikasi sangat bantu saya yang lagi hamil dal...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['solusi', 'ibu', 'hamil']</td>\n",
       "      <td>solusi ibu hamil</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['aplikasi', 'parenting', 'lengkap', 'dan', 'b...</td>\n",
       "      <td>aplikasi parenting lengkap dan baik di indones...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>['nan']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>['padahal', 'bagus', 'suka', 'tapi', 'kenapa',...</td>\n",
       "      <td>padahal bagus suka tapi kenapa sekarang tidak ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>['aplikasi', 'yang', 'sangat', 'bantu', 'untuk...</td>\n",
       "      <td>aplikasi yang sangat bantu untuk saya bagai ib...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>['wow']</td>\n",
       "      <td>wow</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>['moga', 'bantu']</td>\n",
       "      <td>moga bantu</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   processed_tokenized  \\\n",
       "0                                           ['senang']   \n",
       "1    ['mentok', 'melulu', 'di', 'pin', 'tiap', 'mau...   \n",
       "2    ['aplikasi', 'sangat', 'bantu', 'saya', 'yang'...   \n",
       "3                           ['solusi', 'ibu', 'hamil']   \n",
       "4    ['aplikasi', 'parenting', 'lengkap', 'dan', 'b...   \n",
       "..                                                 ...   \n",
       "344                                            ['nan']   \n",
       "345  ['padahal', 'bagus', 'suka', 'tapi', 'kenapa',...   \n",
       "346  ['aplikasi', 'yang', 'sangat', 'bantu', 'untuk...   \n",
       "347                                            ['wow']   \n",
       "348                                  ['moga', 'bantu']   \n",
       "\n",
       "                                        final_sentence Sentiment  \n",
       "0                                               senang  Positive  \n",
       "1    mentok melulu di pin tiap mau log in tidak bis...  Negative  \n",
       "2    aplikasi sangat bantu saya yang lagi hamil dal...  Positive  \n",
       "3                                     solusi ibu hamil  Positive  \n",
       "4    aplikasi parenting lengkap dan baik di indones...  Positive  \n",
       "..                                                 ...       ...  \n",
       "344                                                NaN   Neutral  \n",
       "345  padahal bagus suka tapi kenapa sekarang tidak ...  Negative  \n",
       "346  aplikasi yang sangat bantu untuk saya bagai ib...  Positive  \n",
       "347                                                wow  Positive  \n",
       "348                                         moga bantu  Positive  \n",
       "\n",
       "[349 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:/Coding/school/thesis dhewa/preprocessing/export/full_sentiment_processed_df.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "processed_tokenized    0\n",
       "final_sentence         0\n",
       "Sentiment              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['final_sentence'])\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the aspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA to predict the aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words = [review.split() for review in df['processed_tokenized'].dropna().astype(str)]\n",
    "len(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"['senang']\"], [\"['mentok',\", \"'melulu',\", \"'di',\", \"'pin',\", \"'tiap',\", \"'mau',\", \"'log',\", \"'in',\", \"'tidak',\", \"'bisa',\", \"'masuk',\", \"'terus']\"], [\"['aplikasi',\", \"'sangat',\", \"'bantu',\", \"'saya',\", \"'yang',\", \"'lagi',\", \"'hamil',\", \"'dalam',\", \"'pantau',\", \"'tumbuh',\", \"'kembang',\", \"'janin',\", \"'terima',\", \"'kasih',\", \"'banyak']\"], [\"['solusi',\", \"'ibu',\", \"'hamil']\"], [\"['aplikasi',\", \"'parenting',\", \"'lengkap',\", \"'dan',\", \"'baik',\", \"'di',\", \"'indonesia',\", \"'truncated',\", \"'for',\", \"'brevity']\"]]\n"
     ]
    }
   ],
   "source": [
    "print(data_words[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1)], [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)], [(13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1)], [(28, 1), (29, 1), (30, 1)], [(2, 1), (27, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1)], [(39, 1), (40, 1)], [(41, 1), (42, 1)], [(16, 1), (22, 1), (26, 1), (27, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1)], [(13, 1), (16, 1), (22, 1), (23, 1), (27, 1), (29, 1), (48, 1), (49, 1), (50, 1), (51, 1)], [(6, 1), (11, 1), (18, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1)], [(40, 1), (58, 1)], [(59, 1)], [(17, 1), (18, 1), (19, 1), (49, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1)], [(67, 1), (68, 1)], [(13, 1), (40, 1), (47, 1), (69, 1), (70, 1), (71, 1)], [(15, 1), (27, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1)], [(77, 1), (78, 1), (79, 1), (80, 1), (81, 1)], [(23, 1), (26, 1), (73, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1)], [(2, 1), (18, 1), (23, 1), (65, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1)], [(28, 1), (29, 1), (86, 1), (88, 1), (95, 1), (96, 1)], [(1, 1), (19, 1), (21, 1), (49, 1), (73, 1), (88, 1), (97, 1), (98, 1), (99, 1), (100, 1)], [(34, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1)], [(82, 1), (92, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1)], [(1, 1), (31, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1)], [(121, 1)], [(122, 1)], [(42, 1), (49, 1), (73, 1), (123, 1)], [(28, 1), (45, 1), (124, 1)], [(13, 1), (17, 1), (19, 1), (22, 1), (23, 1), (26, 1), (27, 1), (47, 1), (65, 1), (125, 1)], [(126, 1), (127, 1), (128, 1), (129, 1)], [(13, 1), (16, 1), (40, 1), (73, 1), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1)], [(73, 1), (75, 1), (88, 1), (100, 1), (111, 1), (135, 1)], [(40, 1), (136, 1)], [(137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1)], [(16, 1), (112, 1), (133, 1), (144, 1), (145, 1), (146, 1), (147, 1), (148, 1), (149, 1)], [(150, 1)], [(13, 1), (22, 1), (151, 1), (152, 1), (153, 1)], [(154, 1)], [(26, 1), (40, 1), (44, 1), (69, 1), (155, 1), (156, 1), (157, 1), (158, 1)], [(22, 1), (27, 1), (33, 1), (39, 1), (72, 1)], [(33, 1), (40, 1), (72, 1), (136, 1)], [(121, 1)], [(0, 1)], [(40, 1), (159, 1)], [(160, 1), (161, 1), (162, 1)], [(150, 1)], [(22, 1), (39, 1), (40, 1), (163, 1), (164, 1), (165, 1)], [(27, 1), (47, 1), (72, 1), (166, 1), (167, 1), (168, 1)], [(16, 1), (23, 1), (26, 1), (49, 1), (72, 1), (88, 2), (109, 1), (169, 1), (170, 1), (171, 1), (172, 1)], [(68, 1), (173, 1)], [(174, 1)], [(175, 1)], [(13, 1), (22, 1), (48, 1), (49, 1), (73, 1), (88, 1), (100, 1), (111, 1), (151, 1), (152, 1)], [(33, 1), (40, 1), (72, 1), (176, 1)], [(23, 1), (48, 1), (177, 1), (178, 1)], [(16, 1), (26, 1), (27, 1), (47, 1), (72, 1), (73, 1), (83, 1), (125, 1), (135, 1), (179, 1), (180, 1), (181, 1)], [(22, 1), (49, 1), (116, 1), (136, 1), (148, 1), (182, 1), (183, 1), (184, 1), (185, 1)], [(33, 1), (39, 1), (40, 1), (165, 1)], [(2, 1), (27, 1), (72, 1), (135, 1), (186, 1), (187, 1), (188, 1)], [(189, 1)], [(83, 1), (137, 1), (190, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 2), (196, 1)], [(22, 1), (39, 1), (49, 1), (50, 1), (129, 1)], [(49, 1), (197, 1), (198, 1), (199, 1), (200, 1), (201, 1), (202, 1)], [(203, 1)], [(13, 1), (19, 1), (22, 1), (27, 1), (47, 1), (65, 1), (204, 1), (205, 1), (206, 1)], [(22, 1), (49, 1), (151, 1), (202, 1), (207, 1), (208, 1), (209, 1)], [(26, 1), (27, 1), (33, 1), (47, 1), (152, 1), (210, 1), (211, 1), (212, 1), (213, 1)], [(214, 1)], [(16, 1), (21, 1), (26, 1), (27, 1), (29, 1), (33, 1), (215, 1), (216, 1), (217, 1), (218, 1), (219, 1), (220, 1)], [(34, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1)], [(28, 1), (29, 1), (73, 1), (88, 1), (96, 1), (111, 1), (227, 1)], [(13, 1), (40, 1), (228, 1), (229, 1), (230, 1)], [(22, 1), (27, 1), (39, 1), (72, 1), (73, 1), (135, 1)], [(59, 1)], [(2, 1), (28, 1), (29, 1), (49, 1), (96, 1), (231, 1), (232, 1), (233, 1), (234, 1)], [(47, 1), (73, 1), (129, 1), (235, 1), (236, 2)], [(13, 1), (19, 1), (22, 1), (27, 1), (47, 1), (99, 1), (237, 1)], [(18, 1), (28, 1), (29, 1), (66, 1), (96, 1)], [(238, 1), (239, 1)], [(19, 1), (21, 1), (40, 1), (47, 1), (70, 1), (71, 1), (72, 1)], [(1, 1), (7, 1), (11, 1), (49, 2), (61, 1), (145, 1), (184, 1), (240, 1), (241, 1), (242, 1), (243, 2), (244, 1), (245, 1)], [(22, 1), (26, 1), (27, 1), (39, 1)], [(1, 1), (5, 1), (11, 1), (241, 1), (246, 1), (247, 1), (248, 1), (249, 1), (250, 1)], [(42, 1), (50, 1), (123, 1)], [(73, 1), (88, 1), (92, 1), (246, 1), (251, 1)], [(13, 1), (22, 2), (40, 1), (41, 1)], [(80, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 1), (257, 1), (258, 1), (259, 1), (260, 1)], [(22, 1), (27, 1), (44, 1), (47, 1), (49, 1), (152, 1), (211, 1), (261, 1)], [(23, 1), (26, 1), (27, 1), (31, 1), (262, 1), (263, 1)], [(1, 3), (11, 2), (20, 1), (24, 1), (31, 1), (50, 1), (83, 1), (88, 1), (111, 1), (113, 1), (114, 1), (116, 1), (117, 1), (118, 1), (119, 1), (120, 1), (246, 1), (264, 1), (265, 1), (266, 1), (267, 1), (268, 1), (269, 1), (270, 1), (271, 1), (272, 1), (273, 1), (274, 1), (275, 1), (276, 1)], [(1, 1), (7, 1), (11, 1), (26, 1), (49, 2), (50, 1), (61, 1), (145, 1), (170, 1), (184, 1), (240, 1), (242, 1), (243, 2), (244, 1), (245, 1), (265, 2), (277, 1), (278, 1), (279, 1), (280, 1)], [(1, 1), (2, 1), (5, 1), (11, 1), (20, 1), (23, 1), (26, 1), (31, 1), (69, 1), (212, 1), (213, 1), (246, 1), (247, 1), (248, 1), (249, 1), (250, 1), (265, 1), (277, 1), (281, 1), (282, 1), (283, 1), (284, 1), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 1), (291, 1)], [(26, 1), (292, 1), (293, 1)], [(1, 3), (2, 3), (11, 1), (23, 1), (88, 1), (93, 1), (135, 1), (159, 1), (164, 1), (184, 1), (212, 1), (265, 3), (275, 1), (294, 1), (295, 1), (296, 1), (297, 1), (298, 2), (299, 1), (300, 1), (301, 1)], [(13, 1), (17, 2), (19, 2), (22, 1), (27, 1), (58, 1), (65, 1), (133, 1), (285, 1), (302, 1), (303, 1), (304, 1), (305, 1), (306, 1)], [(2, 1), (11, 2), (15, 1), (19, 1), (31, 1), (33, 1), (49, 1), (55, 1), (62, 1), (72, 1), (82, 1), (83, 3), (116, 2), (168, 2), (244, 1), (307, 2), (308, 1), (309, 1), (310, 1), (311, 1), (312, 1), (313, 1), (314, 1), (315, 1), (316, 1), (317, 2), (318, 3), (319, 1), (320, 1), (321, 1), (322, 1), (323, 1), (324, 1), (325, 1)], [(50, 1), (61, 1), (92, 1), (326, 1), (327, 1), (328, 1)], [(2, 1), (6, 1), (11, 2), (62, 1), (72, 1), (83, 1), (88, 1), (92, 1), (168, 1), (184, 1), (244, 1), (248, 1), (297, 1), (299, 1), (303, 1), (329, 1), (330, 1), (331, 1), (332, 1), (333, 1), (334, 1), (335, 1), (336, 1)], [(337, 1), (338, 1)], [(1, 1), (62, 2), (72, 1), (89, 1), (93, 1), (111, 1), (155, 1), (159, 1), (184, 1), (271, 1), (275, 2), (297, 1), (331, 1), (339, 1), (340, 1), (341, 1), (342, 2), (343, 1), (344, 1), (345, 1), (346, 2), (347, 1), (348, 1), (349, 1)], [(1, 1), (11, 1), (88, 1), (92, 1), (265, 1), (328, 1)], [(79, 1), (259, 1), (279, 1), (350, 1), (351, 1), (352, 1), (353, 1), (354, 1), (355, 1), (356, 1), (357, 1), (358, 1), (359, 1), (360, 1), (361, 1), (362, 1), (363, 1), (364, 1), (365, 1), (366, 1), (367, 2), (368, 1), (369, 1), (370, 1), (371, 2), (372, 1)], [(164, 1), (333, 1), (373, 1), (374, 1)], [(71, 1), (324, 2), (375, 1), (376, 1), (377, 1), (378, 1)], [(106, 1), (379, 1), (380, 1), (381, 1)], [(247, 1), (265, 1), (382, 1), (383, 1), (384, 1)], [(246, 1), (385, 1), (386, 1)], [(80, 3), (190, 1), (352, 1), (354, 1), (387, 1), (388, 1), (389, 1), (390, 1), (391, 1), (392, 1), (393, 1), (394, 1), (395, 1), (396, 2), (397, 1), (398, 1), (399, 1), (400, 1), (401, 1), (402, 1), (403, 1), (404, 1), (405, 1), (406, 1), (407, 1), (408, 1), (409, 1), (410, 1)], [(2, 1), (6, 1), (27, 1), (55, 1), (72, 1), (135, 1), (147, 1), (184, 1), (237, 1), (246, 1), (383, 1), (411, 1), (412, 1), (413, 1), (414, 1), (415, 1), (416, 1), (417, 1)], [(33, 2), (62, 2), (83, 1), (88, 1), (158, 1), (164, 1), (248, 1), (264, 1), (277, 1), (347, 1), (384, 1), (418, 1), (419, 1), (420, 1), (421, 1)], [(1, 1), (11, 1), (26, 1), (71, 1), (88, 1), (181, 1), (285, 1), (422, 1), (423, 1), (424, 1), (425, 1), (426, 1), (427, 1), (428, 1), (429, 1), (430, 1), (431, 1), (432, 1)], [(120, 1), (275, 1), (433, 1), (434, 1)], [(2, 1), (23, 1), (27, 1), (135, 1), (267, 1), (286, 1), (435, 1), (436, 1), (437, 1), (438, 1)], [(125, 1), (155, 1), (162, 1), (439, 1)], [(1, 1), (11, 1), (23, 1), (110, 1), (328, 1), (387, 1), (440, 1), (441, 1), (442, 1), (443, 1)], [(1, 1), (9, 1), (11, 1), (33, 1), (265, 1), (275, 2), (278, 1), (285, 1), (444, 1), (445, 1), (446, 1), (447, 1)], [(2, 2), (23, 1), (110, 1), (133, 2), (146, 1), (168, 2), (179, 1), (215, 1), (268, 1), (384, 1), (412, 1), (448, 1), (449, 2), (450, 1), (451, 1), (452, 1), (453, 1), (454, 1), (455, 1), (456, 1), (457, 1), (458, 1), (459, 2), (460, 2), (461, 1), (462, 2)], [(383, 1), (463, 1), (464, 1), (465, 1)], [(5, 1), (83, 1), (90, 1), (266, 1), (277, 2), (299, 1), (419, 1), (435, 1), (466, 1), (467, 1), (468, 1), (469, 1), (470, 1), (471, 1), (472, 1), (473, 1), (474, 1), (475, 1)], [(11, 1), (27, 1), (272, 1), (476, 1), (477, 1), (478, 1)], [(11, 1), (22, 2), (34, 2), (80, 3), (82, 2), (102, 1), (114, 1), (164, 1), (182, 1), (252, 2), (259, 4), (344, 1), (352, 1), (361, 1), (390, 1), (394, 1), (397, 3), (407, 1), (429, 1), (479, 1), (480, 1), (481, 1), (482, 1), (483, 2), (484, 1), (485, 1), (486, 1), (487, 1), (488, 1), (489, 1), (490, 1), (491, 1), (492, 1), (493, 1), (494, 1), (495, 1), (496, 1), (497, 6), (498, 1), (499, 1), (500, 1), (501, 1), (502, 1), (503, 1), (504, 1), (505, 1), (506, 1), (507, 1), (508, 1), (509, 1), (510, 1), (511, 1), (512, 1), (513, 1), (514, 1), (515, 1), (516, 1), (517, 1), (518, 1), (519, 1), (520, 1), (521, 1), (522, 1), (523, 1), (524, 1), (525, 1), (526, 1)], [(34, 1), (68, 1), (527, 1)], [(11, 1), (23, 1), (248, 1), (268, 1), (275, 1), (333, 1), (388, 1), (463, 1), (528, 1)], [(529, 1), (530, 1), (531, 1), (532, 1)], [(11, 1), (27, 1), (212, 1), (533, 1), (534, 1), (535, 1)], [(26, 1), (100, 1), (131, 1), (536, 1), (537, 1)], [(26, 1), (427, 1), (536, 1), (538, 1)], [(1, 2), (6, 1), (11, 2), (20, 3), (26, 1), (31, 1), (54, 1), (55, 1), (62, 1), (123, 1), (148, 1), (246, 2), (277, 1), (287, 1), (328, 1), (436, 1), (531, 1), (539, 1), (540, 1), (541, 1), (542, 1), (543, 1), (544, 1), (545, 1), (546, 1), (547, 1), (548, 1), (549, 1), (550, 1), (551, 1), (552, 1)], [(10, 1), (11, 1), (23, 2), (312, 1), (328, 1), (553, 1), (554, 1), (555, 1), (556, 1), (557, 1), (558, 1)], [(10, 1), (63, 1), (268, 1), (282, 1), (376, 1), (552, 1), (559, 1), (560, 1), (561, 1), (562, 1), (563, 1), (564, 1)], [(10, 1), (20, 1), (26, 1), (28, 1), (29, 1), (33, 1), (48, 1), (69, 1), (89, 1), (168, 1), (179, 1), (264, 1), (546, 1), (565, 1), (566, 1), (567, 1), (568, 1)], [(1, 1), (9, 1), (11, 1), (62, 1), (110, 1), (184, 1), (248, 1), (312, 1), (387, 1), (443, 1), (569, 1), (570, 1), (571, 1), (572, 1)], [(158, 1), (419, 1), (573, 1), (574, 1)], [(2, 1), (11, 1), (16, 2), (27, 1), (60, 2), (62, 1), (135, 1), (299, 1), (303, 2), (306, 1), (341, 1), (411, 1), (472, 1), (565, 1), (575, 1), (576, 1), (577, 1), (578, 1), (579, 1), (580, 1)], [(1, 1), (6, 1), (11, 1), (23, 2), (26, 2), (72, 1), (83, 1), (88, 1), (93, 1), (147, 1), (159, 1), (184, 1), (212, 1), (275, 1), (297, 1), (374, 1), (444, 1), (446, 1), (581, 1), (582, 1)], [(129, 1), (379, 1)], [(22, 1), (27, 1), (36, 1), (267, 1), (454, 1), (583, 1), (584, 1), (585, 1)], [(15, 1), (16, 2), (26, 1), (65, 1), (93, 1), (129, 1), (163, 1), (179, 1), (181, 1), (184, 1), (249, 1), (297, 1), (308, 2), (312, 1), (560, 1), (586, 1), (587, 1), (588, 1), (589, 1), (590, 1), (591, 1), (592, 1)], [(10, 1), (11, 2), (19, 2), (23, 1), (33, 1), (36, 1), (47, 1), (61, 1), (62, 1), (63, 1), (65, 1), (179, 1), (215, 2), (387, 1), (560, 1), (565, 1), (579, 1), (593, 1), (594, 1), (595, 1), (596, 1), (597, 1), (598, 1), (599, 1), (600, 1), (601, 1), (602, 1), (603, 1), (604, 1), (605, 1)], [(1, 1), (2, 1), (11, 1), (116, 1), (241, 1), (606, 1)], [(1, 1), (2, 1), (386, 1), (607, 1)], [(1, 1), (5, 1), (11, 2), (15, 1), (23, 1), (63, 1), (246, 1), (249, 1), (547, 1), (608, 2), (609, 1), (610, 1), (611, 1), (612, 1), (613, 1)], [(57, 1), (61, 1), (106, 1), (135, 1), (148, 1), (232, 1), (246, 1), (277, 1), (294, 1), (297, 1), (306, 1), (319, 1), (435, 1), (534, 1), (560, 1), (582, 1), (614, 1), (615, 1), (616, 1), (617, 1)], [(39, 1), (618, 1)], [(3, 1), (68, 1), (82, 1), (102, 1), (259, 5), (399, 1), (407, 2), (483, 1), (501, 1), (619, 1), (620, 2), (621, 1), (622, 1), (623, 1), (624, 1), (625, 1), (626, 1), (627, 2), (628, 1), (629, 1)], [(121, 1)], [(1, 1), (11, 2), (232, 1), (302, 1), (306, 1), (328, 1), (630, 1), (631, 2)], [(632, 1)], [(2, 1), (11, 2), (15, 1), (22, 1), (26, 1), (33, 1), (88, 1), (164, 1), (246, 1), (571, 1), (633, 1), (634, 1), (635, 1), (636, 1), (637, 1), (638, 1), (639, 1), (640, 1), (641, 1)], [(275, 1), (298, 1), (438, 1), (469, 1), (642, 1), (643, 1), (644, 1)], [(1, 4), (11, 1), (33, 1), (83, 1), (179, 1), (184, 1), (213, 1), (244, 1), (247, 1), (266, 1), (282, 2), (297, 2), (306, 2), (386, 1), (462, 1), (474, 1), (499, 1), (547, 1), (562, 1), (645, 1), (646, 1), (647, 1), (648, 1), (649, 1), (650, 1)], [(11, 1), (23, 1), (33, 1), (133, 1), (184, 1), (199, 1), (246, 1), (276, 1), (299, 1), (306, 1), (374, 1), (460, 1), (478, 1), (555, 1), (651, 1), (652, 1), (653, 1), (654, 1), (655, 1), (656, 2), (657, 1), (658, 1), (659, 1), (660, 1), (661, 1), (662, 2), (663, 2), (664, 1), (665, 1)], [(6, 1), (11, 1), (57, 1), (73, 1), (244, 1), (272, 1), (306, 1), (327, 1), (630, 1), (666, 1)], [(18, 1), (23, 1), (61, 1), (62, 1), (65, 1), (83, 1), (92, 1), (182, 1), (266, 1), (283, 1), (312, 1), (320, 1), (374, 1), (596, 1), (667, 1), (668, 1), (669, 1)], [(80, 2), (138, 1), (252, 1), (259, 1), (272, 1), (352, 1), (367, 1), (397, 2), (400, 1), (435, 1), (444, 1), (446, 1), (483, 1), (516, 1), (519, 1), (520, 1), (670, 1), (671, 1), (672, 1), (673, 1), (674, 1), (675, 1), (676, 1), (677, 1), (678, 1), (679, 1)], [(2, 1), (62, 1), (135, 1), (268, 1), (383, 1), (463, 1), (606, 1)], [(2, 2), (11, 2), (15, 1), (20, 1), (23, 1), (26, 1), (33, 1), (55, 1), (56, 1), (73, 2), (82, 1), (93, 1), (106, 1), (107, 1), (111, 1), (135, 2), (156, 1), (184, 1), (279, 4), (285, 1), (295, 1), (308, 1), (374, 1), (415, 2), (471, 1), (531, 1), (547, 1), (569, 1), (630, 1), (655, 1), (680, 1), (681, 1), (682, 1), (683, 2), (684, 2), (685, 1), (686, 1), (687, 1), (688, 1), (689, 1), (690, 1), (691, 1)], [(244, 1), (692, 1), (693, 1), (694, 1)], [(1, 1), (2, 2), (11, 2), (26, 1), (50, 1), (60, 1), (61, 2), (63, 1), (106, 1), (111, 1), (135, 1), (213, 1), (265, 2), (268, 1), (306, 1), (331, 1), (463, 1), (547, 1), (695, 1), (696, 1), (697, 1), (698, 1), (699, 1)], [(2, 1), (23, 1), (61, 1), (62, 1), (73, 1), (83, 1), (91, 1), (135, 1), (286, 1), (313, 1), (616, 1), (700, 1)], [(2, 1), (6, 1), (11, 1), (55, 1), (73, 1), (173, 1), (262, 1), (273, 1), (275, 1), (299, 1), (419, 1), (639, 1), (645, 1), (701, 1), (702, 1), (703, 1), (704, 1), (705, 1), (706, 1), (707, 1), (708, 1), (709, 1)], [(2, 1), (7, 1), (83, 1), (92, 1), (252, 1), (710, 1), (711, 1)], [(27, 1), (71, 1), (264, 1), (267, 1), (308, 1), (469, 1), (712, 1)], [(1, 1), (2, 1), (5, 1), (11, 1), (49, 1), (62, 1), (88, 1), (111, 1), (184, 1), (230, 1), (248, 1), (306, 1), (333, 1), (431, 1), (472, 1), (547, 1), (644, 1), (713, 1), (714, 1), (715, 1)], [(22, 1), (34, 1), (82, 1), (182, 1), (248, 1), (259, 1), (367, 1), (397, 1), (497, 1), (509, 1), (516, 1), (716, 1), (717, 1), (718, 1), (719, 1), (720, 1)], [(1, 2), (2, 1), (6, 1), (11, 2), (23, 2), (26, 1), (83, 2), (147, 1), (312, 1), (328, 1), (531, 1), (536, 1), (558, 1), (636, 1), (721, 2)], [(4, 1), (80, 1), (352, 1), (360, 1), (444, 1), (520, 1), (629, 1), (676, 1), (722, 1), (723, 1), (724, 1), (725, 1), (726, 1), (727, 1), (728, 1)], [(11, 1), (20, 1), (26, 1), (63, 1), (91, 1), (115, 1), (116, 1), (240, 1), (277, 1), (285, 1), (306, 1), (460, 1), (478, 1), (562, 1), (729, 1), (730, 1), (731, 1), (732, 1), (733, 1), (734, 1), (735, 1), (736, 1), (737, 1)], [(189, 1)], [(1, 1), (2, 1), (9, 1), (11, 1), (72, 1), (135, 1), (454, 1), (738, 1), (739, 1), (740, 1), (741, 1)], [(49, 1), (55, 1), (62, 1), (168, 1), (265, 1), (299, 1), (312, 1), (328, 1), (346, 1), (531, 1), (692, 1), (742, 1), (743, 1)], [(18, 1), (22, 1), (24, 1), (39, 1), (40, 1), (744, 1), (745, 1)], [(1, 1), (2, 1), (5, 1), (11, 2), (88, 1), (145, 1), (147, 1), (746, 1), (747, 1), (748, 1)], [(1, 1), (16, 1), (28, 1), (306, 1), (335, 1), (386, 1), (547, 1), (550, 1), (749, 1)], [(2, 1), (11, 1), (27, 1), (83, 1), (318, 2), (746, 1), (750, 1)], [(83, 1), (147, 1), (259, 2), (412, 1), (501, 1), (751, 1), (752, 1)], [(2, 1), (6, 1), (11, 1), (73, 1), (116, 1), (237, 1), (279, 1), (297, 1), (562, 1), (630, 1), (753, 1), (754, 1), (755, 1), (756, 1), (757, 1), (758, 1)], [(6, 1), (71, 1), (73, 1), (111, 1), (135, 2), (182, 1), (237, 1), (249, 1), (271, 1), (275, 1), (298, 2), (306, 1), (327, 2), (328, 1), (472, 1), (547, 1), (616, 1), (759, 1)], [(6, 2), (20, 2), (54, 1), (83, 1), (89, 1), (91, 1), (244, 2), (264, 1), (306, 2), (418, 1), (457, 1), (569, 2), (695, 1), (760, 1), (761, 1), (762, 1), (763, 1), (764, 1), (765, 1), (766, 1)], [(1, 1), (65, 1), (99, 1), (218, 1), (228, 1), (767, 1), (768, 1), (769, 1)], [(1, 1), (21, 1), (144, 1), (164, 1), (215, 1), (227, 1), (259, 1), (433, 1), (770, 1), (771, 1), (772, 1)], [(39, 1), (40, 1)], [(27, 1), (58, 1)], [(26, 1), (33, 1), (212, 1), (219, 1), (773, 1), (774, 1), (775, 1)], [(2, 2), (18, 1), (24, 1), (33, 1), (49, 1), (117, 1), (156, 1), (158, 1), (261, 1), (442, 1), (583, 1), (776, 1), (777, 1), (778, 1), (779, 1), (780, 1), (781, 1), (782, 1), (783, 1), (784, 1)], [(34, 1), (785, 1), (786, 1), (787, 1)], [(788, 1)], [(13, 1), (16, 3), (17, 1), (19, 1), (22, 1), (26, 2), (27, 1), (29, 2), (33, 3), (47, 1), (240, 1), (335, 1), (691, 1), (789, 1), (790, 1), (791, 1), (792, 1), (793, 1)], [(159, 1), (794, 1)], [(13, 1), (15, 1), (19, 1), (22, 1), (215, 1), (237, 1), (526, 1), (795, 1), (796, 1)], [(16, 1), (29, 1), (33, 1), (69, 1), (71, 1), (72, 1), (111, 1), (333, 1), (697, 1), (797, 1), (798, 1), (799, 1)], [(26, 1), (27, 1), (58, 1)], [(13, 1), (18, 1), (22, 1), (24, 1), (27, 1), (49, 1), (795, 1), (800, 1)], [(1, 1), (2, 1), (16, 4), (19, 1), (20, 1), (23, 1), (26, 1), (29, 3), (33, 4), (45, 1), (48, 1), (49, 1), (50, 1), (54, 2), (60, 1), (62, 1), (72, 1), (73, 1), (83, 2), (88, 1), (92, 1), (96, 1), (135, 1), (148, 1), (156, 1), (197, 1), (199, 1), (212, 1), (232, 1), (233, 1), (240, 1), (242, 1), (246, 1), (275, 1), (295, 1), (426, 3), (433, 1), (453, 1), (553, 1), (654, 1), (801, 1), (802, 1), (803, 1), (804, 1), (805, 1), (806, 1), (807, 2), (808, 1), (809, 1), (810, 1), (811, 1), (812, 1), (813, 1), (814, 1), (815, 1), (816, 1)], [(40, 1), (58, 1)], [(33, 1), (41, 1), (817, 1), (818, 1)], [(13, 1), (23, 1), (27, 1), (49, 1), (206, 1), (233, 1), (339, 1), (819, 1), (820, 1), (821, 1)], [(13, 1), (24, 1), (162, 1), (269, 1)], [(22, 1), (56, 1), (82, 1), (111, 1), (225, 1), (252, 1), (260, 1), (344, 1), (352, 2), (367, 1), (394, 1), (407, 1), (497, 1), (517, 1), (822, 1), (823, 1), (824, 1), (825, 1), (826, 1), (827, 1), (828, 1), (829, 1), (830, 1)], [(40, 1), (58, 1)], [(121, 1)], [(831, 1)], [(1, 1), (28, 1), (49, 1), (88, 1), (303, 1), (832, 1), (833, 1)], [(152, 1), (211, 1), (283, 2), (433, 1), (634, 1), (635, 1), (789, 1), (834, 1), (835, 1), (836, 1), (837, 1), (838, 1), (839, 1), (840, 1)], [(1, 1), (15, 2), (16, 2), (21, 1), (25, 2), (26, 3), (29, 2), (33, 4), (47, 2), (48, 2), (49, 1), (60, 1), (61, 1), (71, 1), (73, 2), (83, 1), (106, 2), (132, 1), (133, 2), (146, 2), (152, 1), (164, 2), (213, 1), (215, 2), (216, 4), (218, 2), (220, 2), (268, 3), (283, 1), (339, 1), (344, 1), (348, 1), (352, 1), (433, 1), (470, 1), (586, 1), (591, 1), (682, 1), (715, 1), (785, 1), (786, 2), (793, 1), (836, 1), (841, 1), (842, 2), (843, 1), (844, 1), (845, 1), (846, 1), (847, 1), (848, 1), (849, 1), (850, 1), (851, 1), (852, 2), (853, 1)], [(13, 1), (40, 1), (41, 1)], [(260, 1), (505, 1), (854, 1)], [(2, 1), (16, 3), (26, 2), (29, 1), (33, 1), (37, 1), (47, 1), (49, 1), (50, 1), (83, 1), (86, 1), (88, 1), (96, 2), (133, 1), (155, 1), (166, 1), (168, 1), (205, 1), (246, 1), (299, 1), (344, 1), (433, 1), (531, 2), (591, 1), (786, 1), (834, 1), (855, 1), (856, 1), (857, 1), (858, 1), (859, 1)], [(1, 1), (2, 1), (11, 2), (62, 1), (88, 1), (244, 1), (264, 1), (265, 1), (445, 1), (447, 1), (570, 1), (714, 1), (860, 1)], [(50, 1), (360, 1), (861, 1), (862, 1)], [(1, 1), (2, 1), (11, 1), (56, 1), (88, 1), (145, 1), (158, 1), (345, 1), (418, 2), (596, 1), (700, 1), (863, 1), (864, 1), (865, 1), (866, 1)], [(1, 1), (2, 2), (11, 1), (26, 1), (83, 1), (135, 2), (182, 1), (183, 1), (277, 1), (303, 1), (418, 3), (420, 1), (462, 1), (478, 1), (867, 1), (868, 1), (869, 1), (870, 1), (871, 1)], [(58, 1), (417, 1), (421, 1), (547, 1), (872, 1), (873, 1), (874, 1)], [(1, 1), (11, 2), (26, 1), (246, 1), (443, 1), (531, 1), (875, 1), (876, 1)], [(877, 1), (878, 1), (879, 1)], [(5, 1), (20, 1), (23, 2), (33, 1), (49, 1), (88, 1), (91, 1), (148, 1), (230, 1), (232, 1), (248, 1), (268, 1), (438, 1), (462, 1), (631, 1), (713, 1), (880, 1)], [(13, 1), (22, 1), (27, 1), (47, 1), (49, 1), (583, 1), (832, 1), (881, 1)], [(1, 1), (2, 1), (11, 1), (325, 1), (607, 1)], [(879, 1), (882, 1)], [(11, 1), (26, 2), (135, 2), (148, 1), (246, 1), (266, 1), (279, 1), (299, 1), (314, 1), (433, 1), (467, 1), (654, 1), (656, 1), (777, 1), (883, 1), (884, 1), (885, 1), (886, 1), (887, 1), (888, 1), (889, 1), (890, 1), (891, 1)], [(2, 1), (5, 1), (11, 1), (20, 1), (23, 1), (26, 2), (49, 1), (55, 1), (61, 2), (63, 1), (72, 2), (83, 1), (92, 1), (97, 1), (116, 1), (148, 1), (184, 1), (306, 1), (312, 2), (314, 2), (319, 1), (417, 1), (418, 1), (419, 1), (429, 1), (431, 3), (433, 1), (462, 1), (546, 1), (611, 1), (615, 1), (684, 1), (758, 1), (892, 1), (893, 1), (894, 1), (895, 1)], [(13, 1), (125, 1), (199, 1), (338, 1)], [(2, 1), (35, 1), (147, 1), (148, 1), (184, 1), (193, 1), (215, 1), (461, 1), (591, 1), (880, 1), (896, 1), (897, 2), (898, 1)], [(1, 1), (2, 1), (11, 1), (23, 1), (28, 1), (29, 1), (328, 1), (713, 1), (899, 1), (900, 1)], [(1, 1), (5, 1), (11, 2), (184, 1), (193, 1), (246, 1), (248, 1), (275, 1), (306, 1), (312, 1), (325, 1), (388, 1), (433, 1), (713, 1), (798, 1), (901, 1), (902, 1), (903, 1)], [(1, 1), (11, 1), (31, 1), (88, 1), (241, 1), (904, 1)], [(905, 1)], [(71, 1), (83, 1), (123, 1), (181, 1), (277, 1), (569, 1), (611, 1), (906, 1)], [(1, 1), (11, 1), (60, 1), (72, 1), (184, 1), (275, 1), (312, 1), (325, 1), (346, 1), (433, 1), (438, 1), (582, 1), (907, 1)], [(11, 4), (18, 1), (24, 1), (26, 1), (29, 2), (44, 1), (73, 1), (106, 1), (111, 1), (116, 1), (158, 1), (212, 1), (242, 2), (246, 1), (275, 1), (299, 1), (306, 2), (387, 1), (415, 1), (433, 1), (459, 1), (520, 1), (561, 1), (562, 1), (639, 1), (696, 1), (735, 1), (869, 1), (908, 1), (909, 1), (910, 1), (911, 1), (912, 1), (913, 1), (914, 1)], [(1, 1), (2, 1), (11, 1), (88, 1), (89, 1), (92, 1), (135, 1), (246, 1), (265, 1), (275, 1), (312, 1), (328, 1), (655, 1), (762, 1)], [(33, 1), (62, 1), (83, 1), (88, 1), (116, 1), (230, 1), (915, 1), (916, 1)], [(1, 2), (5, 1), (6, 1), (11, 2), (33, 1), (47, 1), (54, 2), (88, 2), (135, 1), (184, 2), (275, 1), (285, 3), (306, 1), (414, 1), (428, 1), (433, 2), (442, 1), (650, 1), (652, 2), (917, 1), (918, 1), (919, 1), (920, 1)], [(1, 1), (39, 1), (71, 1), (921, 1)], [(164, 1), (182, 1), (259, 1), (264, 1), (272, 1), (357, 1), (367, 2), (399, 1), (497, 2), (635, 1), (839, 1), (922, 1), (923, 1), (924, 1), (925, 1), (926, 1)], [(11, 1), (27, 1), (267, 1), (308, 1), (311, 1), (469, 1), (476, 1), (628, 1)], [(6, 1), (10, 1), (83, 1), (265, 1), (266, 1), (268, 1), (534, 1), (535, 1), (616, 1), (927, 1)], [(1, 1), (2, 1), (6, 1), (13, 1), (24, 1), (33, 1), (73, 1), (88, 2), (182, 1), (193, 1), (246, 1), (248, 1), (265, 1), (267, 1), (269, 1), (287, 2), (306, 1), (312, 3), (341, 1), (461, 1), (499, 1), (839, 2), (865, 1), (928, 2), (929, 1), (930, 2), (931, 1), (932, 1)], [(2, 2), (11, 2), (20, 1), (26, 2), (55, 1), (62, 2), (82, 1), (83, 1), (106, 2), (179, 1), (265, 1), (266, 1), (277, 1), (285, 1), (333, 1), (559, 2), (639, 1), (700, 1), (933, 1), (934, 1), (935, 1), (936, 1), (937, 1), (938, 1), (939, 2)], [(1, 1), (11, 1), (26, 1), (83, 1), (184, 1), (286, 1), (387, 1), (418, 1), (438, 1), (570, 1), (869, 2), (906, 1), (940, 1), (941, 1)], [(7, 1), (135, 2), (156, 1), (244, 1), (277, 1), (547, 1), (645, 1), (691, 1), (755, 2), (942, 1), (943, 1), (944, 1), (945, 1), (946, 1)], [(136, 1), (338, 1)], [(1, 1), (2, 1), (3, 1), (4, 1), (11, 2), (83, 1), (92, 1), (277, 1), (476, 1), (700, 1)], [(33, 1), (73, 1), (83, 1), (115, 1), (248, 1), (268, 2), (272, 1), (306, 1), (547, 1), (561, 1), (906, 1)], [(11, 3), (18, 1), (23, 1), (48, 1), (55, 3), (71, 1), (73, 1), (83, 1), (98, 1), (109, 1), (148, 1), (163, 1), (244, 1), (248, 1), (277, 1), (309, 1), (333, 1), (534, 3), (569, 1), (596, 1), (615, 2), (649, 2), (696, 2), (865, 1), (947, 1), (948, 1), (949, 1), (950, 1), (951, 1), (952, 1), (953, 2), (954, 1), (955, 1), (956, 1)], [(2, 1), (5, 1), (11, 1), (19, 1), (26, 1), (89, 1), (111, 1), (193, 1), (216, 1), (312, 1), (418, 1), (816, 1), (957, 1), (958, 1)], [(2, 1), (26, 1), (55, 1), (72, 2), (83, 1), (88, 1), (244, 1), (265, 1), (271, 1), (275, 1), (474, 1), (536, 1), (547, 1), (569, 1), (582, 1), (959, 1), (960, 1), (961, 1)], [(100, 1), (299, 1), (714, 1), (962, 1)], [(82, 1), (259, 1), (501, 1), (963, 1), (964, 1)], [(19, 1), (20, 1), (25, 1), (35, 1), (89, 1), (135, 1), (148, 1), (158, 1), (215, 1), (228, 1), (285, 1), (299, 1), (325, 1), (476, 1), (682, 1), (897, 2), (965, 1), (966, 1), (967, 1)], [(31, 1), (33, 1), (40, 1), (72, 1), (125, 1), (968, 1)], [(225, 2), (268, 1), (275, 1), (969, 1), (970, 1), (971, 1), (972, 1)], [(34, 1), (80, 2), (81, 1), (102, 2), (131, 1), (138, 1), (252, 1), (258, 1), (259, 5), (352, 2), (360, 1), (395, 1), (397, 3), (398, 4), (479, 1), (488, 1), (497, 1), (501, 1), (505, 2), (507, 1), (508, 1), (516, 3), (523, 1), (629, 1), (973, 2), (974, 1), (975, 1), (976, 2), (977, 1), (978, 1), (979, 1), (980, 1), (981, 1), (982, 1), (983, 1), (984, 2), (985, 1), (986, 1), (987, 1), (988, 1), (989, 1), (990, 1), (991, 1), (992, 1), (993, 1), (994, 1), (995, 1)], [(1, 1), (2, 1), (11, 1), (49, 1), (73, 1), (88, 1), (265, 1), (880, 1), (996, 1), (997, 1), (998, 1)], [(999, 1)], [(1, 1), (11, 1), (26, 1), (83, 1), (106, 1), (115, 1), (155, 1), (277, 1), (419, 1), (700, 1), (1000, 1), (1001, 1)], [(1, 1), (11, 1), (33, 1), (40, 1), (459, 1), (460, 1), (565, 1), (685, 1), (1002, 1)], [(16, 1), (19, 1), (33, 1), (40, 1), (47, 1), (69, 1), (84, 1), (206, 1), (238, 1)], [(16, 1), (19, 1), (22, 1), (23, 1), (25, 1), (27, 1), (33, 1), (44, 1), (47, 1), (49, 2), (88, 1), (125, 1), (133, 1), (146, 1), (148, 1), (155, 1), (215, 1), (1003, 1)], [(27, 1), (58, 1), (72, 1), (135, 2), (1004, 1), (1005, 1)], [(16, 2), (22, 1), (26, 2), (29, 1), (86, 1), (88, 1), (125, 1), (155, 1), (181, 1), (212, 1), (215, 1), (233, 1), (1006, 1)], [(1007, 1)], [(19, 1), (48, 1), (50, 1), (70, 1), (71, 1), (124, 1), (1008, 1)], [(129, 1), (200, 1)], [(131, 2), (164, 1), (197, 1), (400, 2), (408, 1), (506, 1), (517, 1), (854, 1), (1009, 1), (1010, 1), (1011, 1), (1012, 1), (1013, 1), (1014, 1)], [(31, 1), (115, 1), (117, 1), (285, 1), (314, 1), (1015, 1), (1016, 1)], [(831, 1)], [(13, 1), (16, 1), (26, 1), (27, 1), (73, 1), (133, 1), (145, 1), (215, 1), (299, 1), (306, 1), (433, 1), (1017, 1), (1018, 1)], [(1019, 1), (1020, 1)], [(16, 1), (19, 1), (21, 1), (26, 1), (29, 1), (44, 1), (47, 1), (73, 2), (88, 1), (100, 1), (132, 1), (433, 1), (789, 1)], [(137, 1), (785, 1), (1021, 1), (1022, 1), (1023, 1), (1024, 1), (1025, 1)], [(2, 1), (40, 1), (44, 1), (47, 1), (152, 1), (1026, 1), (1027, 1), (1028, 1), (1029, 1)], [(40, 1), (41, 1), (44, 1)], [(22, 1), (67, 1), (82, 1), (1030, 1), (1031, 1)], [(22, 1), (26, 1), (27, 1), (167, 1), (591, 1), (1032, 1), (1033, 1)], [(13, 1), (17, 2), (19, 2), (22, 1), (27, 1), (65, 1), (133, 1), (285, 1), (303, 1), (306, 1), (1034, 1), (1035, 1)], [(13, 1), (21, 1), (40, 1), (99, 1)], [(34, 1), (40, 1), (197, 1), (745, 1), (1036, 1)], [(16, 1), (23, 1), (48, 1), (49, 1), (1037, 1), (1038, 1), (1039, 1)], [(2, 1), (23, 1), (26, 1), (33, 1), (69, 1), (166, 1), (564, 1), (1040, 1), (1041, 1)], [(15, 1), (23, 1), (247, 1), (299, 1), (306, 1), (312, 1), (328, 1), (547, 1), (551, 1), (896, 1), (897, 3), (966, 1), (1026, 1)], [(13, 1), (49, 1), (50, 1), (73, 2), (88, 1), (100, 1), (106, 1), (111, 1), (199, 1), (309, 1), (506, 1), (1042, 1)], [(13, 1), (16, 2), (29, 1), (96, 1), (116, 1), (197, 1), (379, 1), (1043, 1)], [(26, 1), (27, 1), (58, 1)], [(16, 1), (29, 1), (47, 1), (96, 1), (110, 1), (338, 1), (715, 1), (1015, 1), (1044, 1)], [(121, 1)], [(22, 1), (27, 1), (33, 1), (49, 1), (72, 1), (136, 1)], [(29, 1), (33, 1), (48, 1), (129, 1), (160, 1), (1045, 1), (1046, 1)], [(39, 1), (129, 1), (193, 1), (1047, 1)], [(1048, 1)], [(1049, 1)], [(40, 1), (1050, 1), (1051, 1)], [(2, 1), (27, 1), (33, 1), (72, 1), (219, 1), (1052, 1)], [(2, 1), (259, 1), (459, 1), (553, 1), (744, 1), (1053, 1), (1054, 1), (1055, 1)], [(6, 1), (16, 1), (33, 1), (49, 1), (148, 1), (215, 1), (285, 2), (295, 1), (375, 1), (433, 1), (713, 1), (1056, 1), (1057, 1), (1058, 1)], [(2, 1), (83, 1), (308, 1), (310, 1), (312, 1), (317, 1), (318, 2), (320, 1), (324, 1), (325, 1), (463, 1), (469, 1)], [(565, 1), (1059, 1), (1060, 1)], [(82, 1), (193, 1), (195, 1), (1061, 1), (1062, 1), (1063, 1), (1064, 1), (1065, 1), (1066, 1)], [(2, 1), (13, 1), (15, 1), (19, 1), (21, 1), (22, 1), (26, 2), (27, 1), (47, 1), (215, 1), (246, 1), (1067, 1)], [(27, 1), (72, 1), (379, 1)], [(13, 1), (16, 1), (22, 1), (26, 1), (27, 1), (29, 1), (33, 1), (47, 1), (1068, 1)], [(13, 1), (16, 1), (23, 1), (26, 1), (27, 1), (155, 1), (233, 1), (1069, 1), (1070, 1)], [(16, 1), (49, 1), (131, 1), (133, 1), (145, 1), (299, 1), (335, 1), (1003, 1), (1018, 1), (1043, 1), (1071, 1)], [(1, 2), (16, 1), (33, 1), (49, 1), (69, 1), (88, 1), (205, 1), (348, 1), (735, 1), (801, 1), (838, 1), (1072, 1)], [(13, 1), (15, 1), (19, 1), (28, 1), (33, 1), (40, 1), (65, 1), (215, 1), (335, 1)], [(16, 1), (26, 1), (27, 1), (45, 1), (133, 1), (134, 1), (145, 1), (148, 1), (215, 1), (306, 1), (387, 1), (433, 1), (1073, 1)], [(6, 1), (11, 1), (72, 1), (83, 1), (184, 1), (248, 1), (299, 1), (333, 1), (336, 1), (1074, 1)], [(13, 1), (22, 1), (23, 1), (26, 1), (27, 1), (29, 1), (47, 1), (215, 1), (283, 1), (1075, 1)], [(1076, 1)], [(39, 1), (338, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "# Create Corpus\n",
    "corpus = [id2word.doc2bow(text) for text in data_words]\n",
    "\n",
    "# View\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.036*\"[\\'aplikasi\\',\" + 0.029*\"\\'bantu\\',\" + 0.022*\"\\'banget\\',\" + '\n",
      "  '0.022*\"\\'sangat\\',\" + 0.015*\"\\'untuk\\',\" + 0.015*\"\\'ini\\',\" + '\n",
      "  '0.008*\"\\'sih\\',\" + 0.008*\"[\\'bantu\\',\" + 0.008*\"\\'asianparent\\']\" + '\n",
      "  '0.008*\"\\'dapat\\',\"'),\n",
      " (1,\n",
      "  '0.020*\"\\'sangat\\',\" + 0.015*\"[\\'aplikasi\\',\" + 0.015*\"\\'sampai\\',\" + '\n",
      "  '0.010*\"\\'ovo\\',\" + 0.010*\"\\'kirim\\',\" + 0.010*\"\\'sudah\\',\" + '\n",
      "  '0.010*\"\\'janin\\',\" + 0.010*\"\\'ini\\',\" + 0.010*\"\\'to\\',\" + '\n",
      "  '0.010*\"\\'saldo\\',\"'),\n",
      " (2,\n",
      "  '0.036*\"[\\'sangat\\',\" + 0.014*\"\\'bantu\\',\" + 0.014*\"\\'saja\\',\" + '\n",
      "  '0.014*\"\\'sudah\\',\" + 0.009*\"\\'janin\\',\" + 0.009*\"\\'iya\\',\" + '\n",
      "  '0.009*\"\\'lagi\\',\" + 0.009*\"\\'komen\\',\" + 0.009*\"\\'begitu\\',\" + '\n",
      "  '0.009*\"\\'dengan\\',\"'),\n",
      " (3,\n",
      "  '0.043*\"\\'tidak\\',\" + 0.036*\"\\'di\\',\" + 0.027*\"\\'nya\\',\" + '\n",
      "  '0.024*\"[\\'aplikasi\\',\" + 0.024*\"\\'bisa\\',\" + 0.018*\"\\'yang\\',\" + '\n",
      "  '0.018*\"\\'buka\\',\" + 0.012*\"\\'baru\\',\" + 0.012*\"\\'lancar\\',\" + '\n",
      "  '0.012*\"\\'terus\\',\"'),\n",
      " (4,\n",
      "  '0.025*\"\\'di\\',\" + 0.021*\"\\'baru\\',\" + 0.021*\"\\'tidak\\',\" + '\n",
      "  '0.018*\"\\'bagus\\',\" + 0.014*\"\\'aplikasi\\',\" + 0.014*\"\\'yang\\',\" + '\n",
      "  '0.014*\"\\'jadi\\',\" + 0.014*\"\\'saya\\',\" + 0.014*\"\\'tapi\\',\" + '\n",
      "  '0.011*\"\\'kenapa\\',\"'),\n",
      " (5,\n",
      "  '0.039*\"\\'untuk\\',\" + 0.020*\"\\'bantu\\',\" + 0.020*\"\\'sangat\\',\" + '\n",
      "  '0.020*\"\\'kembang\\',\" + 0.020*\"[\\'aplikasi\\',\" + 0.020*\"[\\'sangat\\',\" + '\n",
      "  '0.013*\"\\'banget\\',\" + 0.013*\"\\'baik\\',\" + 0.013*\"\\'bisa\\',\" + '\n",
      "  '0.013*\"\\'emak\\',\"'),\n",
      " (6,\n",
      "  '0.023*\"\\'di\\',\" + 0.023*\"\\'hamil\\',\" + 0.020*\"\\'tidak\\',\" + '\n",
      "  '0.017*\"\\'nya\\',\" + 0.017*\"\\'ini\\',\" + 0.017*\"\\'data\\',\" + 0.017*\"\\'yang\\',\" '\n",
      "  '+ 0.017*\"[\\'aplikasi\\',\" + 0.014*\"\\'orang\\',\" + 0.014*\"\\'sekarang\\',\"'),\n",
      " (7,\n",
      "  '0.028*\"\\'ibu\\',\" + 0.028*\"\\'dan\\',\" + 0.028*\"\\'hamil\\',\" + '\n",
      "  '0.020*\"\\'yang\\',\" + 0.017*\"[\\'sangat\\',\" + 0.017*\"\\'bantu\\']\" + '\n",
      "  '0.011*\"\\'teman\\',\" + 0.011*\"\\'bisa\\',\" + 0.011*\"\\'aplikasi\\',\" + '\n",
      "  '0.011*\"\\'fitur\\',\"'),\n",
      " (8,\n",
      "  '0.024*\"\\'bantu\\',\" + 0.024*\"\\'hamil\\',\" + 0.018*\"\\'to\\',\" + '\n",
      "  '0.018*\"\\'ibu\\',\" + 0.012*\"\\'horrible\\',\" + 0.012*\"\\'pantau\\',\" + '\n",
      "  '0.012*\"\\'janin\\']\" + 0.012*\"\\'kita\\',\" + 0.012*\"\\'bisa\\',\" + '\n",
      "  '0.012*\"\\'banget\\',\"'),\n",
      " (9,\n",
      "  '0.037*\"\\'tidak\\',\" + 0.018*\"\\'bisa\\',\" + 0.016*\"\\'dan\\',\" + '\n",
      "  '0.016*\"\\'the\\',\" + 0.015*\"\\'masuk\\',\" + 0.013*\"\\'aplikasi\\',\" + '\n",
      "  '0.013*\"\\'ada\\',\" + 0.013*\"\\'kembang\\',\" + 0.012*\"\\'di\\',\" + '\n",
      "  '0.010*\"\\'kenapa\\',\"'),\n",
      " (10,\n",
      "  '0.034*\"\\'tidak\\',\" + 0.023*\"\\'bisa\\',\" + 0.016*\"\\'aplikasi\\',\" + '\n",
      "  '0.016*\"\\'iya\\',\" + 0.014*\"\\'lagi\\',\" + 0.014*\"\\'yang\\',\" + '\n",
      "  '0.014*\"\\'sudah\\',\" + 0.014*\"\\'ke\\',\" + 0.014*\"\\'dan\\',\" + 0.014*\"\\'di\\',\"'),\n",
      " (11,\n",
      "  '0.021*\"\\'tidak\\',\" + 0.014*\"\\'buka\\',\" + 0.014*\"\\'ini\\',\" + '\n",
      "  '0.014*\"\\'kalau\\',\" + 0.011*\"\\'kuota\\',\" + 0.011*\"\\'bahkan\\',\" + '\n",
      "  '0.011*\"\\'the\\',\" + 0.009*\"\\'just\\',\" + 0.009*\"\\'saja\\',\" + '\n",
      "  '0.009*\"\\'hamil\\',\"'),\n",
      " (12,\n",
      "  '0.031*\"\\'dan\\',\" + 0.028*\"\\'yang\\',\" + 0.020*\"\\'tidak\\',\" + '\n",
      "  '0.020*\"\\'bisa\\',\" + 0.017*\"\\'saya\\',\" + 0.011*\"\\'anak\\',\" + '\n",
      "  '0.011*\"\\'bagai\\',\" + 0.011*\"\\'harus\\',\" + 0.011*\"\\'bayi\\',\" + '\n",
      "  '0.011*\"\\'ini\\',\"'),\n",
      " (13,\n",
      "  '0.022*\"\\'di\\',\" + 0.022*\"\\'saya\\',\" + 0.020*\"\\'yang\\',\" + '\n",
      "  '0.020*\"\\'sangat\\',\" + 0.020*\"\\'bisa\\',\" + 0.018*\"\\'dan\\',\" + '\n",
      "  '0.016*\"\\'harus\\',\" + 0.016*\"\\'sudah\\',\" + 0.016*\"[\\'aplikasi\\',\" + '\n",
      "  '0.013*\"\\'bantu\\',\"'),\n",
      " (14,\n",
      "  '0.021*\"\\'yang\\',\" + 0.018*\"\\'i\\',\" + 0.018*\"\\'bisa\\',\" + 0.018*\"\\'tidak\\',\" '\n",
      "  '+ 0.015*\"\\'sangat\\',\" + 0.015*\"\\'hamil\\',\" + 0.012*\"\\'baru\\',\" + '\n",
      "  '0.012*\"\\'the\\',\" + 0.012*\"\\'ini\\',\" + 0.012*\"[\\'bagus\\',\"')]\n"
     ]
    }
   ],
   "source": [
    "# number of topics\n",
    "num_topics = 15\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LdaMulticore(corpus=corpus, id2word=id2word,\n",
    "                     num_topics=num_topics, iterations=400)\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîπ 2 Positive Aspects\n",
    "1Ô∏è‚É£ Performance & Speed (Positif)\n",
    "\n",
    "Words: cepat, lancar, ringan, smooth, responsif, stabil\n",
    "Why? Many users praise the app‚Äôs speed, responsiveness, and smooth performance.\n",
    "2Ô∏è‚É£ Features & Functionality (Positif)\n",
    "\n",
    "Words: fitur, lengkap, membantu, inovatif, canggih, fungsional\n",
    "Why? Users appreciate useful features, like tracking, e-wallet, and notifications.\n",
    "üîπ 2 Negative Aspects\n",
    "3Ô∏è‚É£ Bugs & Errors (Negatif)\n",
    "\n",
    "Words: error, crash, lambat, tidak bisa, bug, gagal, lemot\n",
    "Why? Complaints about app crashes, errors, and performance issues.\n",
    "4Ô∏è‚É£ App Updates & Changes (Negatif)\n",
    "\n",
    "Words: update, berubah, hilang, downgrade, fitur kurang, tidak sesuai\n",
    "Why? Users dislike bad updates, missing features, or unwanted changes.\n",
    "üîπ 1 Neutral Aspect\n",
    "5Ô∏è‚É£ User Interface & Design (Netral)\n",
    "\n",
    "Words: desain, tampilan, UI, warna, layout, ikon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use these five aspects to create the similarity matrix using FastText embeddings. Each aspect has representative words to help classify sentences based on similarity.\n",
    "\n",
    "Aspect\tSentiment\tKeywords (Example words for similarity)\n",
    "Performance & Speed\tPositive\tcepat, lancar, ringan, smooth, responsif, stabil\n",
    "Features & Functionality\tPositive\tfitur, lengkap, membantu, inovatif, canggih, fungsional\n",
    "Bugs & Errors\tNegative\terror, crash, lambat, tidak bisa, bug, gagal, lemot\n",
    "App Updates & Changes\tNegative\tupdate, berubah, hilang, downgrade, fitur kurang, tidak sesuai\n",
    "User Interface & Design\tNeutral\tdesain, tampilan, UI, warna, layout, ikon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train FastText model\n",
    "fasttext_model = FastText(data_words, vector_size=100, window=5, min_count=5, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aspect keywords\n",
    "aspects = {\n",
    "    \"Performance & Speed\": [\"cepat\", \"lancar\", \"ringan\", \"smooth\", \"responsif\", \"stabil\"],\n",
    "    \"Features & Functionality\": [\"fitur\", \"lengkap\", \"membantu\", \"inovatif\", \"canggih\", \"fungsional\"],\n",
    "    \"Bugs & Errors\": [\"error\", \"crash\", \"lambat\", \"tidak bisa\", \"bug\", \"gagal\", \"lemot\"],\n",
    "    \"App Updates & Changes\": [\"update\", \"berubah\", \"hilang\", \"downgrade\", \"fitur kurang\", \"tidak sesuai\"],\n",
    "    \"User Interface & Design\": [\"desain\", \"tampilan\", \"UI\", \"warna\", \"layout\", \"ikon\"]\n",
    "}\n",
    "\n",
    "# Compute aspect vectors\n",
    "aspect_vectors = {aspect: np.mean([fasttext_model.wv[word] for word in words if word in fasttext_model.wv], axis=0) \n",
    "                  for aspect, words in aspects.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect_similarity(text):\n",
    "    text_vector = np.mean([fasttext_model.wv[word] for word in text if word in fasttext_model.wv], axis=0)\n",
    "    similarities = {aspect: 1 - cosine(text_vector, aspect_vector) for aspect, aspect_vector in aspect_vectors.items()}\n",
    "    return max(similarities, key=similarities.get)  # Return the most similar aspect\n",
    "\n",
    "# Apply to all comments\n",
    "df[\"aspect\"] = df[\"processed_tokenized\"].apply(get_aspect_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_tokenized</th>\n",
       "      <th>final_sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Performance &amp; Speed</th>\n",
       "      <th>Features &amp; Functionality</th>\n",
       "      <th>Bugs &amp; Errors</th>\n",
       "      <th>App Updates &amp; Changes</th>\n",
       "      <th>User Interface &amp; Design</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['senang']</td>\n",
       "      <td>senang</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-0.013929</td>\n",
       "      <td>-0.016290</td>\n",
       "      <td>-0.020538</td>\n",
       "      <td>-0.014177</td>\n",
       "      <td>-0.011142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['mentok', 'melulu', 'di', 'pin', 'tiap', 'mau...</td>\n",
       "      <td>mentok melulu di pin tiap mau log in tidak bis...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.162917</td>\n",
       "      <td>0.167684</td>\n",
       "      <td>0.154058</td>\n",
       "      <td>0.166947</td>\n",
       "      <td>0.177047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['aplikasi', 'sangat', 'bantu', 'saya', 'yang'...</td>\n",
       "      <td>aplikasi sangat bantu saya yang lagi hamil dal...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.122160</td>\n",
       "      <td>0.125455</td>\n",
       "      <td>0.116075</td>\n",
       "      <td>0.123234</td>\n",
       "      <td>0.142130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['solusi', 'ibu', 'hamil']</td>\n",
       "      <td>solusi ibu hamil</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.131804</td>\n",
       "      <td>0.135719</td>\n",
       "      <td>0.125913</td>\n",
       "      <td>0.135160</td>\n",
       "      <td>0.150845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['aplikasi', 'parenting', 'lengkap', 'dan', 'b...</td>\n",
       "      <td>aplikasi parenting lengkap dan baik di indones...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.132960</td>\n",
       "      <td>0.136111</td>\n",
       "      <td>0.124924</td>\n",
       "      <td>0.135307</td>\n",
       "      <td>0.141645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>['aplikasi', 'yang', 'pakai', 'dari', 'awal', ...</td>\n",
       "      <td>aplikasi yang pakai dari awal program hamil sa...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.129241</td>\n",
       "      <td>0.132980</td>\n",
       "      <td>0.120835</td>\n",
       "      <td>0.131961</td>\n",
       "      <td>0.154155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>['padahal', 'bagus', 'suka', 'tapi', 'kenapa',...</td>\n",
       "      <td>padahal bagus suka tapi kenapa sekarang tidak ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.115574</td>\n",
       "      <td>0.118651</td>\n",
       "      <td>0.106650</td>\n",
       "      <td>0.117571</td>\n",
       "      <td>0.141891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>['aplikasi', 'yang', 'sangat', 'bantu', 'untuk...</td>\n",
       "      <td>aplikasi yang sangat bantu untuk saya bagai ib...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.133465</td>\n",
       "      <td>0.134439</td>\n",
       "      <td>0.125045</td>\n",
       "      <td>0.134813</td>\n",
       "      <td>0.148984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>['wow']</td>\n",
       "      <td>wow</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.198535</td>\n",
       "      <td>0.193159</td>\n",
       "      <td>0.186851</td>\n",
       "      <td>0.201718</td>\n",
       "      <td>0.173089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>['moga', 'bantu']</td>\n",
       "      <td>moga bantu</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.148567</td>\n",
       "      <td>0.145708</td>\n",
       "      <td>0.140866</td>\n",
       "      <td>0.153375</td>\n",
       "      <td>0.194110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   processed_tokenized  \\\n",
       "0                                           ['senang']   \n",
       "1    ['mentok', 'melulu', 'di', 'pin', 'tiap', 'mau...   \n",
       "2    ['aplikasi', 'sangat', 'bantu', 'saya', 'yang'...   \n",
       "3                           ['solusi', 'ibu', 'hamil']   \n",
       "4    ['aplikasi', 'parenting', 'lengkap', 'dan', 'b...   \n",
       "..                                                 ...   \n",
       "343  ['aplikasi', 'yang', 'pakai', 'dari', 'awal', ...   \n",
       "345  ['padahal', 'bagus', 'suka', 'tapi', 'kenapa',...   \n",
       "346  ['aplikasi', 'yang', 'sangat', 'bantu', 'untuk...   \n",
       "347                                            ['wow']   \n",
       "348                                  ['moga', 'bantu']   \n",
       "\n",
       "                                        final_sentence Sentiment  \\\n",
       "0                                               senang  Positive   \n",
       "1    mentok melulu di pin tiap mau log in tidak bis...  Negative   \n",
       "2    aplikasi sangat bantu saya yang lagi hamil dal...  Positive   \n",
       "3                                     solusi ibu hamil  Positive   \n",
       "4    aplikasi parenting lengkap dan baik di indones...  Positive   \n",
       "..                                                 ...       ...   \n",
       "343  aplikasi yang pakai dari awal program hamil sa...  Positive   \n",
       "345  padahal bagus suka tapi kenapa sekarang tidak ...  Negative   \n",
       "346  aplikasi yang sangat bantu untuk saya bagai ib...  Positive   \n",
       "347                                                wow  Positive   \n",
       "348                                         moga bantu  Positive   \n",
       "\n",
       "     Performance & Speed  Features & Functionality  Bugs & Errors  \\\n",
       "0              -0.013929                 -0.016290      -0.020538   \n",
       "1               0.162917                  0.167684       0.154058   \n",
       "2               0.122160                  0.125455       0.116075   \n",
       "3               0.131804                  0.135719       0.125913   \n",
       "4               0.132960                  0.136111       0.124924   \n",
       "..                   ...                       ...            ...   \n",
       "343             0.129241                  0.132980       0.120835   \n",
       "345             0.115574                  0.118651       0.106650   \n",
       "346             0.133465                  0.134439       0.125045   \n",
       "347             0.198535                  0.193159       0.186851   \n",
       "348             0.148567                  0.145708       0.140866   \n",
       "\n",
       "     App Updates & Changes  User Interface & Design  \n",
       "0                -0.014177                -0.011142  \n",
       "1                 0.166947                 0.177047  \n",
       "2                 0.123234                 0.142130  \n",
       "3                 0.135160                 0.150845  \n",
       "4                 0.135307                 0.141645  \n",
       "..                     ...                      ...  \n",
       "343               0.131961                 0.154155  \n",
       "345               0.117571                 0.141891  \n",
       "346               0.134813                 0.148984  \n",
       "347               0.201718                 0.173089  \n",
       "348               0.153375                 0.194110  \n",
       "\n",
       "[310 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_aspect_similarities(text):\n",
    "    text_vector = np.mean([fasttext_model.wv[word] for word in text if word in fasttext_model.wv], axis=0)\n",
    "\n",
    "    # Compute cosine similarity for each aspect\n",
    "    similarities = {aspect: 1 - cosine(text_vector, aspect_vector) for aspect, aspect_vector in aspect_vectors.items()}\n",
    "    \n",
    "    return similarities  # Return dictionary with all scores\n",
    "\n",
    "# Apply function to all reviews\n",
    "df_aspect_scores = df[\"processed_tokenized\"].apply(get_aspect_similarities).apply(pd.Series)\n",
    "\n",
    "# Merge with original DataFrame\n",
    "df_final = df.join(df_aspect_scores)\n",
    "\n",
    "# Show the first few rows\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>final_sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>predicted_aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>senang</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mentok melulu di pin tiap mau log in tidak bis...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>User Interface &amp; Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aplikasi sangat bantu saya yang lagi hamil dal...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>User Interface &amp; Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>solusi ibu hamil</td>\n",
       "      <td>Positive</td>\n",
       "      <td>User Interface &amp; Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aplikasi parenting lengkap dan baik di indones...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>User Interface &amp; Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>aplikasi yang pakai dari awal program hamil sa...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>padahal bagus suka tapi kenapa sekarang tidak ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>aplikasi yang sangat bantu untuk saya bagai ib...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>User Interface &amp; Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>wow</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Features &amp; Functionality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>moga bantu</td>\n",
       "      <td>Positive</td>\n",
       "      <td>User Interface &amp; Design</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        final_sentence Sentiment  \\\n",
       "0                                               senang  Positive   \n",
       "1    mentok melulu di pin tiap mau log in tidak bis...  Negative   \n",
       "2    aplikasi sangat bantu saya yang lagi hamil dal...  Positive   \n",
       "3                                     solusi ibu hamil  Positive   \n",
       "4    aplikasi parenting lengkap dan baik di indones...  Positive   \n",
       "..                                                 ...       ...   \n",
       "305  aplikasi yang pakai dari awal program hamil sa...  Positive   \n",
       "306  padahal bagus suka tapi kenapa sekarang tidak ...  Negative   \n",
       "307  aplikasi yang sangat bantu untuk saya bagai ib...  Positive   \n",
       "308                                                wow  Positive   \n",
       "309                                         moga bantu  Positive   \n",
       "\n",
       "             predicted_aspect  \n",
       "0                      Others  \n",
       "1     User Interface & Design  \n",
       "2     User Interface & Design  \n",
       "3     User Interface & Design  \n",
       "4     User Interface & Design  \n",
       "..                        ...  \n",
       "305                       NaN  \n",
       "306                       NaN  \n",
       "307   User Interface & Design  \n",
       "308  Features & Functionality  \n",
       "309   User Interface & Design  \n",
       "\n",
       "[310 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_aspect(row):\n",
    "    max_sim = row.max()  # Get the highest similarity score\n",
    "    if max_sim < 0:  \n",
    "        return \"Others\"  # If all values are negative, assign \"Others\"\n",
    "    return row.idxmax()  # Otherwise, assign the aspect with the highest similarity\n",
    "\n",
    "# Apply the function to each row of similarity scores\n",
    "df_final[\"predicted_aspect\"] = df_aspect_scores.apply(assign_aspect, axis=1)\n",
    "\n",
    "# Show results\n",
    "df_final[['final_sentence', 'Sentiment', 'predicted_aspect']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_tokenized</th>\n",
       "      <th>final_sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Performance &amp; Speed</th>\n",
       "      <th>Features &amp; Functionality</th>\n",
       "      <th>Bugs &amp; Errors</th>\n",
       "      <th>App Updates &amp; Changes</th>\n",
       "      <th>User Interface &amp; Design</th>\n",
       "      <th>predicted_aspect</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['senang']</td>\n",
       "      <td>senang</td>\n",
       "      <td>Positive</td>\n",
       "      <td>-0.013929</td>\n",
       "      <td>-0.016290</td>\n",
       "      <td>-0.020538</td>\n",
       "      <td>-0.014177</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>Others</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['mentok', 'melulu', 'di', 'pin', 'tiap', 'mau...</td>\n",
       "      <td>mentok melulu di pin tiap mau log in tidak bis...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.162917</td>\n",
       "      <td>0.167684</td>\n",
       "      <td>0.154058</td>\n",
       "      <td>0.166947</td>\n",
       "      <td>0.177047</td>\n",
       "      <td>User Interface &amp; Design</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['aplikasi', 'sangat', 'bantu', 'saya', 'yang'...</td>\n",
       "      <td>aplikasi sangat bantu saya yang lagi hamil dal...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.122160</td>\n",
       "      <td>0.125455</td>\n",
       "      <td>0.116075</td>\n",
       "      <td>0.123234</td>\n",
       "      <td>0.142130</td>\n",
       "      <td>User Interface &amp; Design</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['solusi', 'ibu', 'hamil']</td>\n",
       "      <td>solusi ibu hamil</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.131804</td>\n",
       "      <td>0.135719</td>\n",
       "      <td>0.125913</td>\n",
       "      <td>0.135160</td>\n",
       "      <td>0.150845</td>\n",
       "      <td>User Interface &amp; Design</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['aplikasi', 'parenting', 'lengkap', 'dan', 'b...</td>\n",
       "      <td>aplikasi parenting lengkap dan baik di indones...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.132960</td>\n",
       "      <td>0.136111</td>\n",
       "      <td>0.124924</td>\n",
       "      <td>0.135307</td>\n",
       "      <td>0.141645</td>\n",
       "      <td>User Interface &amp; Design</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>['aplikasi', 'yang', 'pakai', 'dari', 'awal', ...</td>\n",
       "      <td>aplikasi yang pakai dari awal program hamil sa...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.129241</td>\n",
       "      <td>0.132980</td>\n",
       "      <td>0.120835</td>\n",
       "      <td>0.131961</td>\n",
       "      <td>0.154155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>['padahal', 'bagus', 'suka', 'tapi', 'kenapa',...</td>\n",
       "      <td>padahal bagus suka tapi kenapa sekarang tidak ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.115574</td>\n",
       "      <td>0.118651</td>\n",
       "      <td>0.106650</td>\n",
       "      <td>0.117571</td>\n",
       "      <td>0.141891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>['aplikasi', 'yang', 'sangat', 'bantu', 'untuk...</td>\n",
       "      <td>aplikasi yang sangat bantu untuk saya bagai ib...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.133465</td>\n",
       "      <td>0.134439</td>\n",
       "      <td>0.125045</td>\n",
       "      <td>0.134813</td>\n",
       "      <td>0.148984</td>\n",
       "      <td>User Interface &amp; Design</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>['wow']</td>\n",
       "      <td>wow</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.198535</td>\n",
       "      <td>0.193159</td>\n",
       "      <td>0.186851</td>\n",
       "      <td>0.201718</td>\n",
       "      <td>0.173089</td>\n",
       "      <td>Features &amp; Functionality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>['moga', 'bantu']</td>\n",
       "      <td>moga bantu</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.148567</td>\n",
       "      <td>0.145708</td>\n",
       "      <td>0.140866</td>\n",
       "      <td>0.153375</td>\n",
       "      <td>0.194110</td>\n",
       "      <td>User Interface &amp; Design</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   processed_tokenized  \\\n",
       "0                                           ['senang']   \n",
       "1    ['mentok', 'melulu', 'di', 'pin', 'tiap', 'mau...   \n",
       "2    ['aplikasi', 'sangat', 'bantu', 'saya', 'yang'...   \n",
       "3                           ['solusi', 'ibu', 'hamil']   \n",
       "4    ['aplikasi', 'parenting', 'lengkap', 'dan', 'b...   \n",
       "..                                                 ...   \n",
       "305  ['aplikasi', 'yang', 'pakai', 'dari', 'awal', ...   \n",
       "306  ['padahal', 'bagus', 'suka', 'tapi', 'kenapa',...   \n",
       "307  ['aplikasi', 'yang', 'sangat', 'bantu', 'untuk...   \n",
       "308                                            ['wow']   \n",
       "309                                  ['moga', 'bantu']   \n",
       "\n",
       "                                        final_sentence Sentiment  \\\n",
       "0                                               senang  Positive   \n",
       "1    mentok melulu di pin tiap mau log in tidak bis...  Negative   \n",
       "2    aplikasi sangat bantu saya yang lagi hamil dal...  Positive   \n",
       "3                                     solusi ibu hamil  Positive   \n",
       "4    aplikasi parenting lengkap dan baik di indones...  Positive   \n",
       "..                                                 ...       ...   \n",
       "305  aplikasi yang pakai dari awal program hamil sa...  Positive   \n",
       "306  padahal bagus suka tapi kenapa sekarang tidak ...  Negative   \n",
       "307  aplikasi yang sangat bantu untuk saya bagai ib...  Positive   \n",
       "308                                                wow  Positive   \n",
       "309                                         moga bantu  Positive   \n",
       "\n",
       "     Performance & Speed  Features & Functionality  Bugs & Errors  \\\n",
       "0              -0.013929                 -0.016290      -0.020538   \n",
       "1               0.162917                  0.167684       0.154058   \n",
       "2               0.122160                  0.125455       0.116075   \n",
       "3               0.131804                  0.135719       0.125913   \n",
       "4               0.132960                  0.136111       0.124924   \n",
       "..                   ...                       ...            ...   \n",
       "305             0.129241                  0.132980       0.120835   \n",
       "306             0.115574                  0.118651       0.106650   \n",
       "307             0.133465                  0.134439       0.125045   \n",
       "308             0.198535                  0.193159       0.186851   \n",
       "309             0.148567                  0.145708       0.140866   \n",
       "\n",
       "     App Updates & Changes  User Interface & Design          predicted_aspect  \\\n",
       "0                -0.014177                -0.011142                    Others   \n",
       "1                 0.166947                 0.177047   User Interface & Design   \n",
       "2                 0.123234                 0.142130   User Interface & Design   \n",
       "3                 0.135160                 0.150845   User Interface & Design   \n",
       "4                 0.135307                 0.141645   User Interface & Design   \n",
       "..                     ...                      ...                       ...   \n",
       "305               0.131961                 0.154155                       NaN   \n",
       "306               0.117571                 0.141891                       NaN   \n",
       "307               0.134813                 0.148984   User Interface & Design   \n",
       "308               0.201718                 0.173089  Features & Functionality   \n",
       "309               0.153375                 0.194110   User Interface & Design   \n",
       "\n",
       "     y  \n",
       "0    1  \n",
       "1    0  \n",
       "2    1  \n",
       "3    1  \n",
       "4    1  \n",
       "..  ..  \n",
       "305  1  \n",
       "306  0  \n",
       "307  1  \n",
       "308  1  \n",
       "309  1  \n",
       "\n",
       "[310 rows x 10 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define mapping for Sentiment\n",
    "sentiment_mapping = {\"Positive\": 1, \"Neutral\": 1, \"Negative\": 0}\n",
    "\n",
    "# Apply mapping to create \"y\" column\n",
    "df_final[\"y\"] = df_final[\"Sentiment\"].map(sentiment_mapping)\n",
    "\n",
    "# Display first few rows\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    IMG_SIZE = (224,224)\n",
    "    DEVICE = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    FOLDS = 5\n",
    "    SHUFFLE = True\n",
    "    BATCH_SIZE = 32\n",
    "    LR = 0.01\n",
    "    EPOCHS = 30\n",
    "    EMB_DIM = 100\n",
    "    MAX_LEN = 20\n",
    "    MODEL_PATH = \"./Models/MyModel.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate torch dataset\n",
    "\n",
    "class Vocabulary:\n",
    "  \n",
    "    '''\n",
    "    __init__ method is called by default as soon as an object of this class is initiated\n",
    "    we use this method to initiate our vocab dictionaries\n",
    "    '''\n",
    "    def __init__(self, freq_threshold, max_size):\n",
    "        '''\n",
    "        freq_threshold : the minimum times a word must occur in corpus to be treated in vocab\n",
    "        max_size : max source vocab size. Eg. if set to 10,000, we pick the top 10,000 most frequent words and discard others\n",
    "        '''\n",
    "        #initiate the index to token dict\n",
    "        ## <PAD> -> padding, used for padding the shorter sentences in a batch to match the length of longest sentence in the batch\n",
    "        ## <SOS> -> start token, added in front of each sentence to signify the start of sentence\n",
    "        ## <EOS> -> End of sentence token, added to the end of each sentence to signify the end of sentence\n",
    "        ## <UNK> -> words which are not found in the vocab are replace by this token\n",
    "        self.itos = {0: '<PAD>', 1:'<SOS>', 2:'<EOS>', 3: '<UNK>'}\n",
    "        #initiate the token to index dict\n",
    "        self.stoi = {k:j for j,k in self.itos.items()} \n",
    "        \n",
    "        self.freq_threshold = freq_threshold\n",
    "        self.max_size = max_size\n",
    "    \n",
    "    '''\n",
    "    __len__ is used by dataloader later to create batches\n",
    "    '''\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "    \n",
    "    '''\n",
    "    a simple tokenizer to split on space and converts the sentence to list of words\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def tokenizer(text):\n",
    "        return [tok.lower().strip() for tok in text.split(' ')]\n",
    "    \n",
    "    '''\n",
    "    build the vocab: create a dictionary mapping of index to string (itos) and string to index (stoi)\n",
    "    output ex. for stoi -> {'the':5, 'a':6, 'an':7}\n",
    "    '''\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        #calculate the frequencies of each word first to remove the words with freq < freq_threshold\n",
    "        frequencies = {}  #init the freq dict\n",
    "        idx = 4 #index from which we want our dict to start. We already used 4 indexes for pad, start, end, unk\n",
    "        \n",
    "        #calculate freq of words\n",
    "        for sentence in sentence_list:\n",
    "            for word in self.tokenizer(sentence):\n",
    "                if word not in frequencies.keys():\n",
    "                    frequencies[word]=1\n",
    "                else:\n",
    "                    frequencies[word]+=1\n",
    "                    \n",
    "                    \n",
    "        #limit vocab by removing low freq words\n",
    "        frequencies = {k:v for k,v in frequencies.items() if v>self.freq_threshold} \n",
    "        \n",
    "        #limit vocab to the max_size specified\n",
    "        frequencies = dict(sorted(frequencies.items(), key = lambda x: -x[1])[:self.max_size-idx]) # idx =4 for pad, start, end , unk\n",
    "            \n",
    "        #create vocab\n",
    "        for word in frequencies.keys():\n",
    "            self.stoi[word] = idx\n",
    "            self.itos[idx] = word\n",
    "            idx+=1\n",
    "            \n",
    "     \n",
    "    '''\n",
    "    convert the list of words to a list of corresponding indexes\n",
    "    '''    \n",
    "    def numericalize(self, text):\n",
    "        #tokenize text\n",
    "        tokenized_text = self.tokenizer(text)\n",
    "        numericalized_text = []\n",
    "        for token in tokenized_text:\n",
    "            if token in self.stoi.keys():\n",
    "                numericalized_text.append(self.stoi[token])\n",
    "            else: #out-of-vocab words are represented by UNK token index\n",
    "                numericalized_text.append(self.stoi['<UNK>'])\n",
    "                \n",
    "        return numericalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "    Initiating Variables\n",
    "    df: the training dataframe\n",
    "    source_column : the name of source text column in the dataframe\n",
    "    transform : If we want to add any augmentation\n",
    "    freq_threshold : the minimum times a word must occur in corpus to be treated in vocab\n",
    "    source_vocab_max_size : max source vocab size\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, df, source_column,freq_threshold = 3,\n",
    "                source_vocab_max_size = 10000 , transform=None):\n",
    "    \n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "        #get source and target texts\n",
    "        self.source_texts = self.df[source_column]\n",
    "        \n",
    "        \n",
    "        ##VOCAB class has been created above\n",
    "        #Initialize source vocab object and build vocabulary\n",
    "        self.source_vocab = Vocabulary(freq_threshold, source_vocab_max_size)\n",
    "        self.source_vocab.build_vocabulary(self.source_texts.tolist())\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    '''\n",
    "    __getitem__ runs on 1 example at a time. Here, we get an example at index and return its numericalize source and\n",
    "    target values using the vocabulary objects we created in __init__\n",
    "    '''\n",
    "    def __getitem__(self, index):\n",
    "        source_text = self.source_texts[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            source_text = self.transform(source_text)\n",
    "            \n",
    "        #numericalize texts ['<SOS>','cat', 'in', 'a', 'bag','<EOS>'] -> [1,12,2,9,24,2]\n",
    "        numerialized_source = [self.source_vocab.stoi[\"<SOS>\"]]\n",
    "        numerialized_source += self.source_vocab.numericalize(source_text)\n",
    "        numerialized_source.append(self.source_vocab.stoi[\"<EOS>\"])\n",
    "        \n",
    "        #convert the list to tensor and return\n",
    "        return torch.tensor(numerialized_source), torch.tensor(self.df.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CustomDataset(df_final, \"final_sentence\")\n",
    "len(dataset.source_vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/dataset-new', 'wb') as dataset_file:\n",
    " \n",
    "  # Step 3\n",
    "    pickle.dump(dataset, dataset_file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_layer_with_weights(target_vocab, emb_model, trainable = False):\n",
    "\n",
    "    weights_matrix = np.zeros((len(target_vocab), config.EMB_DIM))\n",
    "    words_found = 0\n",
    "    \n",
    "    for i, word in enumerate(target_vocab):\n",
    "        weights_matrix[i] = np.concatenate([emb_model.wv[word]])\n",
    "        words_found += 1\n",
    "                \n",
    "    print(f\"Words found are : {words_found}\")\n",
    "    \n",
    "    weights_matrix = torch.tensor(weights_matrix, dtype = torch.float32).reshape(len(target_vocab), config.EMB_DIM)\n",
    "    emb_layer = nn.Embedding.from_pretrained(weights_matrix)\n",
    "    print(emb_layer)\n",
    "    if trainable:\n",
    "        emb_layer.weight.requires_grad = True\n",
    "    else:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollate:\n",
    "    def __init__(self, pad_idx, maxlen):\n",
    "        self.pad_idx = pad_idx\n",
    "        self.maxlen = maxlen\n",
    "        \n",
    "    \n",
    "    #__call__: a default method\n",
    "    ##   First the obj is created using MyCollate(pad_idx) in data loader\n",
    "    ##   Then if obj(batch) is called -> __call__ runs by default\n",
    "    def __call__(self, batch):\n",
    "        #get all source indexed sentences of the batch\n",
    "        source = [item[0] for item in batch] \n",
    "        #pad them using pad_sequence method from pytorch. \n",
    "#         source = pad_sequence(source, batch_first=False, padding_value = self.pad_idx)\n",
    "        \n",
    "        padded_sequence = torch.zeros((self.maxlen, len(batch)), dtype = torch.int)\n",
    "        \n",
    "        for idx, text in enumerate(source):\n",
    "            \n",
    "            if len(text) > self.maxlen:\n",
    "                padded_sequence[:, idx] = source[idx][: self.maxlen]\n",
    "            else:\n",
    "                padded_sequence[:len(source[idx]), idx] = padded_sequence[:len(source[idx]), idx] + source[idx]\n",
    "                \n",
    "        \n",
    "        #get all target indexed sentences of the batch\n",
    "        target = [item[1] for item in batch] \n",
    "        \n",
    "        target = torch.tensor(target, dtype = torch.float32).reshape(-1)\n",
    "        return padded_sequence, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, embedding_layer):\n",
    "        super().__init__()\n",
    "#         self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = embedding_layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional = True)\n",
    "        self.fc1 = nn.Linear(2*hidden_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        max_len, N = text.shape\n",
    "        hidden = torch.zeros((2, N , self.hidden_dim),\n",
    "                          dtype=torch.float)\n",
    "        memory = torch.zeros((2, N , self.hidden_dim),\n",
    "                          dtype=torch.float)\n",
    "        hidden = hidden.to(config.DEVICE)\n",
    "        memory = memory.to(config.DEVICE)\n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.lstm(embedded, (hidden, memory))\n",
    "#         assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        y_pred = output[-1,:,:]\n",
    "        y_pred = self.fc1(y_pred)\n",
    "        y_pred = self.fc2(y_pred)\n",
    "        y_pred = self.sigmoid(y_pred)\n",
    "                         \n",
    "        return y_pred  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(dataloader, model, loss_fn, optimizer):\n",
    "    train_correct = 0\n",
    "    train_loss = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for review, label in tqdm(dataloader):\n",
    "        \n",
    "        review, label = review.to(config.DEVICE), label.to(config.DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(review)\n",
    "        output = output.reshape(-1)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * review.size(1)\n",
    "        prediction = (output > 0.5).float()  # Convert to binary\n",
    "        train_correct += (prediction == label).float().sum()\n",
    "        \n",
    "        all_labels.extend(label.cpu().numpy())\n",
    "        all_predictions.extend(prediction.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    train_acc = (train_correct / len(dataloader.dataset)) * 100\n",
    "    \n",
    "    # Ensure both labels and predictions are binary before passing to confusion matrix\n",
    "    all_labels = [int(label) for label in all_labels]  # Ensure labels are integers\n",
    "    all_predictions = [int(pred) for pred in all_predictions]  # Ensure predictions are integers\n",
    "    \n",
    "    return train_loss, train_acc, all_labels, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epochs(dataloader, model, loss_fn):\n",
    "    val_correct = 0\n",
    "    val_loss = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for review, label in dataloader:\n",
    "        \n",
    "        review, label = review.to(config.DEVICE), label.to(config.DEVICE)\n",
    "        \n",
    "        output = model(review)\n",
    "        output = output.reshape(-1)\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        \n",
    "        val_loss += loss.item() * review.size(1)\n",
    "        prediction = (output > 0.5).float()  # Convert to binary\n",
    "        val_correct += (prediction == label).float().sum()\n",
    "\n",
    "        all_labels.extend(label.cpu().numpy())\n",
    "        all_predictions.extend(prediction.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    val_acc = (val_correct / len(dataloader.dataset)) * 100\n",
    "    \n",
    "    # Ensure both labels and predictions are binary before passing to confusion matrix\n",
    "    all_labels = [int(label) for label in all_labels]  # Ensure labels are integers\n",
    "    all_predictions = [int(pred) for pred in all_predictions]  # Ensure predictions are integers\n",
    "    \n",
    "    return val_loss, val_acc, all_labels, all_predictions\n",
    "\n",
    "\n",
    "best_val_acc = 0  # Track the best validation accuracy\n",
    "best_fold = None  # Store the fold number with the best validation accuracy\n",
    "best_model_state_dict = None  # Store the best model state dict\n",
    "best_train_loss = None  # Store the best training loss\n",
    "best_val_loss = None  # Store the best validation loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words found are : 208\n",
      "Embedding(208, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 42.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6899268823919944 | Val Loss : 0.6789893003610464 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 42.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6853866484558698 | Val Loss : 0.6703912799174969 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6824605528590748 | Val Loss : 0.6660288480611948 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 43.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6811945507827314 | Val Loss : 0.6618398565512437 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 45.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6802406073773949 | Val Loss : 0.6593526189143841 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 46.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6803646081859626 | Val Loss : 0.6590642745678241 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 46.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6798184872830956 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.6564922699561486 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 45.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.679775118249134 | Val Loss : 0.6559144808695867 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 45.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6806078205988245 | Val Loss : 0.6557122377248911 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6803823935175405 | Val Loss : 0.6579920053482056 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 46.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.680199615006308 | Val Loss : 0.6586255522874686 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 50.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6813789062129642 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.6595571407904992 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 48.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6810707380470721 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.6608431339263916 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 51.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6801913693113234 | Val Loss : 0.6607264234469488 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 50.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6802205865822949 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.658913832444411 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 48.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6800022391439642 | Val Loss : 0.6570455386088445 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 48.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6797627881892676 | Val Loss : 0.6550300350556006 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6797184324958949 | Val Loss : 0.6541527051192063 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 51.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6798001956013799 | Val Loss : 0.6559121746283311 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 52.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6800699135632191 | Val Loss : 0.6567034354576697 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6796660226525613 | Val Loss : 0.6559275388717651 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6797434473500669 | Val Loss : 0.6567443930185758 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 52.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6797529482147069 | Val Loss : 0.6564366404826825 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6800477001273516 | Val Loss : 0.6554653323613681 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 52.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.679723615206561 | Val Loss : 0.6536029898203336 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6796316035742899 | Val Loss : 0.654123631807474 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6797000401228377 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.6562571342174823 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6796579117913848 | Val Loss : 0.6567463737267715 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 50.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6797566141897035 | Val Loss : 0.6568768803889935 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 42.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6796914987193728 | Val Loss : 0.6569053943340595 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n",
      "Words found are : 208\n",
      "Embedding(208, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 48.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6958211910897407 | Val Loss : 0.6938648536367323 | Train Acc : 30.967742919921875 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6727495029352714 | Val Loss : 0.6994865224199388 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6587166005862508 | Val Loss : 0.7067342967662996 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6522846610649772 | Val Loss : 0.7138516249008549 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 48.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6479479794341009 | Val Loss : 0.7197769961310821 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 46.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6460948828337849 | Val Loss : 0.7243670531846944 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 50.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6454016511566973 | Val Loss : 0.7265994774485097 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 29.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6445291986787952 | Val Loss : 0.7328679850957927 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 50.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6439796501887594 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.7356421606054584 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6441410468972247 | Val Loss : 0.7362402891649783 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 57.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6435785437551673 | Val Loss : 0.7389426283466006 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 48.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6433217773115002 | Val Loss : 0.7383211457613602 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 51.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6442463919160447 | Val Loss : 0.7421463542771571 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 46.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6434471244397371 | Val Loss : 0.7403667106211764 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 51.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6437986349138085 | Val Loss : 0.7403531196047959 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.643925831945622 | Val Loss : 0.7453925858423548 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6432455115848117 | Val Loss : 0.7470040425513554 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 52.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6443025037862252 | Val Loss : 0.7463637960767283 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 48.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6434345009246311 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.7452467708911711 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6432672862845342 | Val Loss : 0.7437468275283147 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6433035339710217 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.7431788103094379 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 48.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6438458253795974 | Val Loss : 0.7368917042769275 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6439161338092049 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.7426355128149384 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 38.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.643593082393425 | Val Loss : 0.741445883385186 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6434159952661266 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.7395988882166667 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6432848667752915 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.739041931420854 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 27.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6435735490587022 | Val Loss : 0.7374513357588388 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 46.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6433780406408264 | Val Loss : 0.7372205784019915 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 45.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6436419121309179 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.7350745727714983 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 45.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6435599361640819 | Val Loss : 0.7353058769864943 | Train Acc : 43.870967864990234 | Val Acc : 16.774194717407227 |\n",
      "Words found are : 208\n",
      "Embedding(208, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6892788603110014 | Val Loss : 0.6771254990864726 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6851255597123778 | Val Loss : 0.672467841685397 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6843132414103706 | Val Loss : 0.669748045287086 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 50.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.682865646150377 | Val Loss : 0.6651858878367155 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 50.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6820874542429827 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.6625173207625602 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.68189437435445 | Val Loss : 0.6593594973527112 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 46.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6811877201144821 | Val Loss : 0.658027587006393 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 44.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6809077510511242 | Val Loss : 0.656974976502576 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 41.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6809244023429023 | Val Loss : 0.6559296655423433 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 50.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6807447640216293 | Val Loss : 0.6538956147953144 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6807650195227729 | Val Loss : 0.653483766953922 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6805550507877184 | Val Loss : 0.6542336738225326 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 48.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.680561175380928 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.6540201468375123 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 45.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6809161077950887 | Val Loss : 0.6551812285358466 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 28.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6807850472593077 | Val Loss : 0.6538129379448382 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 51.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6804850222407908 | Val Loss : 0.6538795365870578 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6808379295367549 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.6521051375611314 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 46.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6808715989624244 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.6528945513141965 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6809021171164398 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.6528003348887546 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 48.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6807687564748497 | Val Loss : 0.6535240758969946 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6806025104822168 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.6521168466910575 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 49.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6809641854198658 | Val Loss : 0.6524666657725584 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 40.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.681229513336495 | Val Loss : 0.6511707132302441 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 45.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6807767414816336 | Val Loss : 0.6518663329985536 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 46.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6809317196048976 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.65265070176819 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 46.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6812593968594132 | Val Loss : 0.6524825964159179 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 50.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6806359023287676 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.6518308080515816 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 46.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6813570511513862 | Val Loss : 0.6521261826302241 | Train Acc : 38.70967483520508 | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 51.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6813953294270281 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss : 0.6529887318611145 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 47.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6811242909823063 | Val Loss : 0.6530883468470527 | Train Acc : 38.70967483520508 | Val Acc : 21.935483932495117 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model (Fold 0):\n",
      "Train Accuracy: 38.70967483520508\n",
      "Validation Accuracy: 21.935483932495117\n",
      "Train Loss: 0.6796914987193728\n",
      "Validation Loss: 0.6569053943340595\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize tracking variables\n",
    "best_train_acc = 0\n",
    "best_val_acc = 0\n",
    "best_cm = None  # Store confusion matrix for the best fold\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(np.arange(len(dataset)))):\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=config.BATCH_SIZE, sampler=train_sampler, collate_fn=MyCollate(0, config.MAX_LEN))\n",
    "    val_loader = DataLoader(dataset, batch_size=config.BATCH_SIZE, sampler=val_sampler, collate_fn=MyCollate(0, config.MAX_LEN))\n",
    "\n",
    "    VOCAB_SIZE = len(dataset.source_vocab)\n",
    "    HIDDEN_DIM = 128\n",
    "    OUTPUT_DIM = 1\n",
    "    VOCAB = list(dataset.source_vocab.stoi)\n",
    "\n",
    "    embedding_layer = get_emb_layer_with_weights(target_vocab=VOCAB, emb_model=fasttext_model, trainable=False)\n",
    "\n",
    "    model = Model(VOCAB_SIZE, config.EMB_DIM, HIDDEN_DIM, OUTPUT_DIM, embedding_layer)\n",
    "    model = model.to(config.DEVICE)\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "    # Train and validation metrics for this fold\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(config.EPOCHS):\n",
    "        train_loss, train_acc, _, _ = train_epochs(train_loader, model, loss_fn, optimizer)\n",
    "        val_loss, val_acc, _, _ = val_epochs(val_loader, model, loss_fn)\n",
    "\n",
    "        train_loss = train_loss / len(train_loader.sampler)\n",
    "        val_loss = val_loss / len(val_loader.sampler)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        # Print the results for each epoch\n",
    "        print(f\"| Train Loss : {train_loss} |\", end=\" \")\n",
    "        print(f\"Val Loss : {val_loss} |\", end=\" \")\n",
    "        print(f\"Train Acc : {train_acc} |\", end=\" \")\n",
    "        print(f\"Val Acc : {val_acc} |\")\n",
    "\n",
    "    # After all epochs in this fold, check if this fold's validation accuracy is the best\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_train_acc = train_acc\n",
    "        best_val_loss = val_loss\n",
    "        best_train_loss = train_loss\n",
    "        best_fold = fold\n",
    "        best_model_state_dict = model.state_dict()\n",
    "        best_cm = confusion_matrix(_, _)  # Use the best labels and predictions from this fold\n",
    "\n",
    "# Print the best results\n",
    "print(f\"\\nBest Model (Fold {best_fold}):\")\n",
    "print(f\"Train Accuracy: {best_train_acc}\")\n",
    "print(f\"Validation Accuracy: {best_val_acc}\")\n",
    "print(f\"Train Loss: {best_train_loss}\")\n",
    "print(f\"Validation Loss: {best_val_loss}\")\n",
    "\n",
    "# Plot the confusion matrix for the best fold after all epochs are done\n",
    "plot_confusion_matrix(best_cm, title=\"Best Fold Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can save the best model if desired\n",
    "torch.save(best_model_state_dict, \"model/My-Model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(dataloader, model, loss_fn, optimizer):\n",
    "    train_correct = 0\n",
    "    train_loss = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for review, label in tqdm(dataloader):\n",
    "        \n",
    "        review, label = review.to(config.DEVICE), label.to(config.DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(review)\n",
    "        output = output.reshape(-1)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * review.size(1)\n",
    "        \n",
    "        # Modify prediction to 0, 0.5, or 1 based on the output\n",
    "        prediction = torch.where(output < 0.25, torch.tensor(0.0), \n",
    "                                 torch.where(output < 0.75, torch.tensor(0.5), torch.tensor(1.0)))\n",
    "        \n",
    "        # Count correct predictions\n",
    "        train_correct += (prediction == label).float().sum()\n",
    "        \n",
    "        all_labels.extend(label.cpu().numpy())\n",
    "        all_predictions.extend(prediction.cpu().numpy())\n",
    "\n",
    "    train_acc = (train_correct / len(dataloader.dataset)) * 100\n",
    "    \n",
    "    return train_loss, train_acc, all_labels, all_predictions\n",
    "\n",
    "def val_epochs(dataloader, model, loss_fn):\n",
    "    val_correct = 0\n",
    "    val_loss = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for review, label in dataloader:\n",
    "        \n",
    "        review, label = review.to(config.DEVICE), label.to(config.DEVICE)\n",
    "        \n",
    "        output = model(review)\n",
    "        output = output.reshape(-1)\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        \n",
    "        val_loss += loss.item() * review.size(1)\n",
    "        \n",
    "        # Modify prediction to 0, 0.5, or 1 based on the output\n",
    "        prediction = torch.where(output < 0.25, torch.tensor(0.0), \n",
    "                                 torch.where(output < 0.75, torch.tensor(0.5), torch.tensor(1.0)))\n",
    "        \n",
    "        val_correct += (prediction == label).float().sum()\n",
    "\n",
    "        all_labels.extend(label.cpu().numpy())\n",
    "        all_predictions.extend(prediction.cpu().numpy())\n",
    "    \n",
    "    val_acc = (val_correct / len(dataloader.dataset)) * 100\n",
    "    \n",
    "    return val_loss, val_acc, all_labels, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 25.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6694911345358818 | Val Loss : 0.6690710298476681 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 36.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6697748414931759 | Val Loss : 0.6690645217895508 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 46.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6696968928460152 | Val Loss : 0.6691485574168544 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 43.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6697839056291888 | Val Loss : 0.6690836237322899 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 48.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6692982631344949 | Val Loss : 0.6690742765703509 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 46.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6694462110919337 | Val Loss : 0.6689478270469174 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 46.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6694830659897096 | Val Loss : 0.668931120826352 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 46.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6702146653206118 | Val Loss : 0.668914419604886 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 51.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6699872424525599 | Val Loss : 0.6689007028456657 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 46.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6696327886273784 | Val Loss : 0.668893547211924 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 47.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6691228901186297 | Val Loss : 0.6688782818855777 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 51.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6694165233642825 | Val Loss : 0.6688515555474066 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 42.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6692253347366087 | Val Loss : 0.6688318087208656 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 46.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.66973261333281 | Val Loss : 0.6688157243113364 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 40.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.669955873873926 | Val Loss : 0.668792183937565 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 43.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6699928668237501 | Val Loss : 0.6687798469297348 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 48.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6692641777376975 | Val Loss : 0.6687562492585951 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 48.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6699490916344427 | Val Loss : 0.6687402367591858 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 45.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6697961415013959 | Val Loss : 0.6687641978263855 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 46.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6696513245182653 | Val Loss : 0.6687633495176992 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 46.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.669152997386071 | Val Loss : 0.6688143718627191 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 39.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6693271560053672 | Val Loss : 0.6686795673062724 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 44.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6689305347781027 | Val Loss : 0.6686402590044083 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 49.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6694100610671505 | Val Loss : 0.6686192831685466 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 48.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6693093780548341 | Val Loss : 0.668606839641448 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 49.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6690191980331175 | Val Loss : 0.6686101825006546 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 43.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6692617804773392 | Val Loss : 0.6685573581726321 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 29.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.668847454747846 | Val Loss : 0.6685416075491136 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 48.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6695075361959396 | Val Loss : 0.6685119459705968 | Train Acc : 0.0 | Val Acc : 0.0 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 45.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss : 0.6690904517327586 | Val Loss : 0.6684889289640611 | Train Acc : 0.0 | Val Acc : 0.0 |\n",
      "\n",
      "Model Performance Metrics after Training:\n",
      "Accuracy: 0.6064516129032258\n",
      "Recall: 1.0\n",
      "F1 Score: 0.7550200803212851\n",
      "Confusion Matrix:\n",
      "[[   0 3660]\n",
      " [   0 5640]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Initialize tracking variables for all metrics\n",
    "all_true_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "# Train the model for all epochs\n",
    "for epoch in range(config.EPOCHS):\n",
    "    train_loss, train_acc, _, _ = train_epochs(train_loader, model, loss_fn, optimizer)\n",
    "    val_loss, val_acc, _, _ = val_epochs(val_loader, model, loss_fn)\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.sampler)\n",
    "    val_loss = val_loss / len(val_loader.sampler)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    # After validation, collect true labels and predictions\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        true_labels = []\n",
    "        preds = []\n",
    "        probs = []  # Store probabilities for AUC calculation\n",
    "        for data, label in val_loader:\n",
    "            output = model(data)\n",
    "            \n",
    "            # Apply sigmoid to get probabilities (keep as tensor)\n",
    "            prob = torch.sigmoid(output).cpu()  # Ensure it's a tensor\n",
    "            predictions = torch.round(prob)  # Convert probabilities to binary predictions (0 or 1)\n",
    "            \n",
    "            true_labels.extend(label.cpu().numpy())\n",
    "            preds.extend(predictions.cpu().numpy())\n",
    "            probs.extend(prob.cpu().numpy())  # Store probabilities for AUC calculation\n",
    "\n",
    "        # Store the true labels and predictions for metrics calculation\n",
    "        all_true_labels.extend(true_labels)\n",
    "        all_preds.extend(preds)\n",
    "        all_probs.extend(probs)\n",
    "\n",
    "    # Print the results for each epoch\n",
    "    print(f\"| Train Loss : {train_loss} |\", end=\" \")\n",
    "    print(f\"Val Loss : {val_loss} |\", end=\" \")\n",
    "    print(f\"Train Acc : {train_acc} |\", end=\" \")\n",
    "    print(f\"Val Acc : {val_acc} |\")\n",
    "\n",
    "# Calculate performance metrics after all epochs\n",
    "accuracy = accuracy_score(all_true_labels, all_preds)\n",
    "recall = recall_score(all_true_labels, all_preds)\n",
    "f1 = f1_score(all_true_labels, all_preds)\n",
    "cm = confusion_matrix(all_true_labels, all_preds)  # Confusion matrix\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"\\nModel Performance Metrics after Training:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
